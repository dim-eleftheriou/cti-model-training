{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc9d074b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 10-09 13:19:21 [__init__.py:244] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "from unsloth import FastLanguageModel\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43f77dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sft_model = \"/mnt/data/training-outputs/Llama-3.1-8B-Malware-Expert/checkpoint-271\"\n",
    "sft_model = \"/mnt/data/training-outputs/Llama-3.1-8B-Malware-Expert-r128-a256/checkpoint-306\"\n",
    "\n",
    "#sft_model = \"/home/deleftheriou/cti-model-training/Llama-3.1-8B-Instruct-DPO-Malware-Expert/checkpoint-393\"\n",
    "\n",
    "sft_system_message = \"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all malwares referenced or implied in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe malwares.\n",
    "                    To describe a malware you should provide the fields id, type, name and is_family.\n",
    "                    Instead of using UUID in the id field, use the rule type--name for generating ids.\n",
    "                    If no malwares are identified return a json with an empty list \"objects\".\n",
    "                    Identify all malwares in the folowing CTI report: \"\"\"\n",
    "\n",
    "# sft_system_message_2 = \"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "#                  Your task is to identify all malwares referenced or implied in a CTI report. \n",
    "#                  You MUST return a json with a field \"objects\" being a list of json objects that describe malwares.\n",
    "#                  To describe a malware you should provide the fields id, type, name and is_family.\n",
    "#                  Instead of using UUID in the id field, use the rule type--name for generating ids.\n",
    "#                  For example, an output in which the malware RandomMalware is identified and is not family\n",
    "#                  of some other malware should be like this:\n",
    "                 \n",
    "#                  {\n",
    "#                      \"objects\": [\n",
    "#                          {\n",
    "#                              \"id\": \"malware--RandomMalware\",\n",
    "#                              \"type\": \"malware\",\n",
    "#                              \"name\": \"RandomMalware\",\n",
    "#                              \"is_family\": false\n",
    "#                          }\n",
    "#                      ]\n",
    "#                  }\n",
    "                 \n",
    "#                  If no malwares are identified return a json with an empty list \"objects\".\n",
    "#                  Identify all malwares in the folowing CTI report: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899d9ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.8: Fast Llama patching. Transformers: 4.53.0. vLLM: 0.9.1.\n",
      "   \\\\   /|    NVIDIA H100 PCIe. Num GPUs = 1. Max memory: 79.179 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 9.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62ab3999c464f4b910038adf801c7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.6.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = sft_model,\n",
    "    fast_inference = False,\n",
    "    load_in_4bit = False,\n",
    "    max_seq_length = None,\n",
    "    gpu_memory_utilization = 0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "040fa6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "def format_input_prompt(system_message, user_input):\n",
    "    formatted_input = [\n",
    "        {\"role\": \"assistant\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "    return formatted_input\n",
    "\n",
    "def format_validation_example_for_inference(example):\n",
    "    return example.split(\"<|start_header_id|>user<|end_header_id|>\")[1].split(\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")[0]\n",
    "\n",
    "def inference(model, system_message, user_input, max_new_tokens=None, **kwargs):\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        format_input_prompt(system_message, user_input),\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors = \"pt\").to(\"cuda\")\n",
    "    if not max_new_tokens:\n",
    "        max_new_tokens = model.config.max_position_embeddings - input_ids.shape[-1]\n",
    "    model.generate(input_ids, streamer = text_streamer, max_new_tokens=max_new_tokens, **kwargs)\n",
    "\n",
    "def predict(model, system_message, user_input, max_new_tokens=None, **kwargs):\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        format_input_prompt(system_message, user_input),\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors = \"pt\").to(\"cuda\")\n",
    "    if not max_new_tokens:\n",
    "        max_new_tokens = model.config.max_position_embeddings - input_ids.shape[-1]\n",
    "    \n",
    "    output_ids = model.generate(input_ids, max_new_tokens=max_new_tokens, **kwargs)\n",
    "    result = tokenizer.batch_decode(output_ids)\n",
    "    processed_result = result[0].split(\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\")[-1].split(\"<|eot_id|>\")[0]\n",
    "    return processed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1757c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path:str, filename:str):\n",
    "    with open(os.path.join(path, filename), mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def format_example(example:dict, system_message):\n",
    "        formatted_example = [\n",
    "            {\"role\": \"assistant\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "            {\"role\": \"assistant\", \"content\": json.dumps(example[\"output\"])}\n",
    "        ]\n",
    "        return formatted_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7abbeda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"/mnt/data/openCTI/splitted-io-pairs/test\"\n",
    "inputs = []\n",
    "outputs = []\n",
    "include_cti_type = [\"malware\"]\n",
    "\n",
    "for file in os.listdir(test_path):\n",
    "    cti_type = file.split(\"--\")[0]\n",
    "    if cti_type not in include_cti_type:\n",
    "        continue\n",
    "    example = load_json(test_path, file)\n",
    "    inputs.append(example[\"input\"])\n",
    "    outputs.append(example[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b2216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outputs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf87972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"objects\": [{\"id\": \"\", \"type\": \"malware\", \"name\": \"BlueSky\", \"is_family\": false}]}\n"
     ]
    }
   ],
   "source": [
    "system_message = sft_system_message\n",
    "user_input = inputs[3]\n",
    "inference(model,\n",
    "          system_message, \n",
    "          user_input, \n",
    "          max_new_tokens=500,\n",
    "          temperature=0.9,\n",
    "          top_p=0.9,\n",
    "          repetition_penalty=1.1,\n",
    "          no_repeat_ngram_size=3,\n",
    "          do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f2e29f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "LlamaForCausalLM has no `_prepare_4d_causal_attention_mask_with_cache_position` method defined in its base modeling class. Compiled forward passes will be sub-optimal. If you're writing code, see Llama for an example implementation. If you're a user, please report this issue on GitHub.\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:40<00:00,  2.00s/it]\n"
     ]
    }
   ],
   "source": [
    "system_message = sft_system_message\n",
    "inputs = inputs[:50]\n",
    "outputs = outputs[:50]\n",
    "\n",
    "preds = [predict(model,\n",
    "                 system_message,\n",
    "                 user_input,\n",
    "                 max_new_tokens=500,\n",
    "                 temperature=0.6,\n",
    "                 top_p=0.2,\n",
    "                 repetition_penalty=1.1,\n",
    "                 no_repeat_ngram_size=3,\n",
    "                 do_sample=True) for user_input in tqdm(inputs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f34ae5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds4eval = []\n",
    "failed_preds = []\n",
    "pattern = r'\\{\\s*\"id\"\\s*:\\s*\"[^\"]*\"\\s*,\\s*\"type\"\\s*:\\s*\"[^\"]*\"\\s*,\\s*\"name\"\\s*:\\s*\"[^\"]*\"\\s*,\\s*\"is_family\"\\s*:\\s*(?:true|false|null|\"(?:[^\"]*)\"|[-+]?\\d+(?:\\.\\d+)?)\\s*\\}'\n",
    "\n",
    "for p in preds:\n",
    "    try:\n",
    "        preds4eval.append(\n",
    "            {\n",
    "                \"objects\":json.loads(p.lower())[\"objects\"]\n",
    "            }\n",
    "        )\n",
    "    except:\n",
    "        objects = re.findall(pattern, p)\n",
    "        if not objects:\n",
    "            failed_preds.append(p)\n",
    "        else:\n",
    "            valid_objs = [json.loads(obj) for obj in objects]\n",
    "        preds4eval.append(\n",
    "            {\n",
    "                \"objects\":valid_objs\n",
    "                }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c26447f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percenrage of failed json outputs: 14.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Percenrage of failed json outputs: {'{:.1f}'.format(100 * len(failed_preds) / len(inputs))}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05b613fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post processing\n",
    "processed_preds4eval = []\n",
    "\n",
    "def fix_malware_id(wrong_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Fixes malformed malware IDs according to the observed patterns.\n",
    "    \"\"\"\n",
    "\n",
    "    # Trim spaces\n",
    "    s = wrong_id.strip().lower()\n",
    "\n",
    "    # Remove leading underscores or hyphens\n",
    "    s = re.sub(r'^[-_]+', '', s)\n",
    "\n",
    "    # Remove redundant 'malware' if itâ€™s at the start but malformed\n",
    "    s = re.sub(r'^(malware[-_]+)', '', s)\n",
    "\n",
    "    # Handle duplicated name parts (e.g., 'fatboy--fatboy')\n",
    "    parts = re.split(r'--+', s)\n",
    "    if len(parts) == 2 and parts[0] == parts[1]:\n",
    "        s = parts[0]\n",
    "\n",
    "    # Prepend 'malware--'\n",
    "    corrected = f\"malware--{s}\"\n",
    "\n",
    "    # Ensure only one double dash after 'malware'\n",
    "    corrected = re.sub(r'^malware-+', 'malware--', corrected)\n",
    "\n",
    "    return corrected\n",
    "\n",
    "# Step 1\n",
    "for p in preds4eval:\n",
    "    objects = []\n",
    "    for obj in p[\"objects\"]:\n",
    "        # Step 1\n",
    "        if \"id\" in obj.keys():\n",
    "            ID = fix_malware_id(obj[\"id\"].strip())\n",
    "            NAME = ID.split(\"malware--\")[-1]\n",
    "\n",
    "        # if \"name\" in obj.keys():\n",
    "        #     NAME = obj[\"name\"]\n",
    "\n",
    "        if \"is_family\" in obj.keys():\n",
    "            IS_FAMILY = obj[\"is_family\"]\n",
    "        else:\n",
    "            IS_FAMILY = False\n",
    "\n",
    "        objects.append(\n",
    "            {\n",
    "                \"id\":ID,\n",
    "                \"type\":\"malware\",\n",
    "                \"name\":NAME,\n",
    "                \"is_family\":IS_FAMILY\n",
    "            }\n",
    "        )\n",
    "\n",
    "    processed_preds4eval.append(\n",
    "                {\n",
    "                    \"objects\":objects\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "badff28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.stix_evaluator import STIXEvaluator\n",
    "\n",
    "evaluator = STIXEvaluator(comparison_values=[\"id\"], cti_object_types=[\"malware\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b2f2ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precison: 0.56757\n",
      "Recall: 0.32812\n",
      "F1-Score: 0.41584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deleftheriou/cti-model-training/evaluation/stix_evaluator.py:271: STIXWarning: \n",
      "Type and Name will be used to compare stix objects!\n",
      "  warnings.warn(\"\\nType and Name will be used to compare stix objects!\", STIXWarning)\n",
      "/home/deleftheriou/cti-model-training/evaluation/stix_evaluator.py:276: STIXWarning: \n",
      "All cti types will be evaluated!\n",
      "  warnings.warn(\"\\nAll cti types will be evaluated!\", STIXWarning)\n"
     ]
    }
   ],
   "source": [
    "p, r, f1, full_res = evaluator._evaluate_(predicted=processed_preds4eval, actual=outputs)\n",
    "print(f\"Precison: {p}\\nRecall: {r}\\nF1-Score: {f1}\")\n",
    "\n",
    "# Temperature 0.2\n",
    "# Min_p 0.2\n",
    "# Precison: 0.7\n",
    "# Recall: 0.4375\n",
    "# F1-Score: 0.53846\n",
    "\n",
    "# Temperature 0.2\n",
    "# Min_p 0.1\n",
    "# Precison: 0.7\n",
    "# Recall: 0.4375\n",
    "# F1-Score: 0.53846\n",
    "\n",
    "# Temperature 0.7\n",
    "# Min_p 0.2\n",
    "# Precison: 0.7\n",
    "# Recall: 0.4375\n",
    "# F1-Score: 0.53846\n",
    "\n",
    "# Temperature 0.1\n",
    "# Min_p 0.1\n",
    "# Precison: 0.7\n",
    "# Recall: 0.4375\n",
    "# F1-Score: 0.53846\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e4767",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Detailed results:\\n {full_res}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
