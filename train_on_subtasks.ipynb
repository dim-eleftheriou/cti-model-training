{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e780d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 09-23 14:04:42 [__init__.py:244] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import json\n",
    "\n",
    "import os\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "num_proc = cpu_count()\n",
    "\n",
    "import yaml\n",
    "\n",
    "from data_processor import SplittedJsonIoDataset\n",
    "from customs import customize_tokenizer\n",
    "\n",
    "from unsloth import UnslothTrainer, UnslothTrainingArguments\n",
    "\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq, DataCollatorForLanguageModeling\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "from unsloth import unsloth_train\n",
    "\n",
    "from utils import save_log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c674da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path:str, filename:str):\n",
    "    with open(os.path.join(path, filename), mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def format_example(example:dict, system_message):\n",
    "        formatted_example = [\n",
    "            {\"role\": \"assistant\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "            {\"role\": \"assistant\", \"content\": json.dumps(example[\"output\"])}\n",
    "        ]\n",
    "        return formatted_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e171c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_messages = {\n",
    "    \"domain-name\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all domain names referenced in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe domain names.\n",
    "                    To describe a domain name you should provide the fields id, type and value.\n",
    "                    Instead of using UUID in the id field, use the rule type--value for generating ids.\n",
    "                    If no domain names are identified return a json with an empty list \"objects\".\n",
    "                    Identify all domain names in the folowing CTI report: \"\"\",\n",
    "\n",
    "    \"hostname\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all hostnames referenced in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe hostnames.\n",
    "                    To describe a hostname you should provide the fields id, type and value.\n",
    "                    Instead of using UUID in the id field, use the rule type--value for generating ids.\n",
    "                    If no hostnames are identified return a json with an empty list \"objects\".\n",
    "                    Identify all hostnames in the folowing CTI report: \"\"\",\n",
    "\n",
    "    \"url\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all URLs referenced in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe URLs.\n",
    "                    To describe a URL you should provide the fields id, type and value.\n",
    "                    Instead of using UUID in the id field, use the rule type--value for generating ids.\n",
    "                    If no URLs are identified return a json with an empty list \"objects\".\n",
    "                    Identify all URLs in the folowing CTI report: \"\"\",\n",
    "\n",
    "    \"email-addr\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all email addresses referenced in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe email addresses.\n",
    "                    To describe an email address you should provide the fields id, type and value.\n",
    "                    Instead of using UUID in the id field, use the rule type--value for generating ids.\n",
    "                    If no email addresses are identified return a json with an empty list \"objects\".\n",
    "                    Identify all email addresses in the folowing CTI report: \"\"\",\n",
    "\n",
    "    \"ipv4-addr\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all ipv4-addresses referenced in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe ipv4-addresses.\n",
    "                    To describe an ipv4-address you should provide the fields id, type and value.\n",
    "                    Instead of using UUID in the id field, use the rule type--value for generating ids.\n",
    "                    If no ipv4-addresses are identified return a json with an empty list \"objects\".\n",
    "                    Identify all ipv4-addresses in the folowing CTI report: \"\"\",\n",
    "\n",
    "    \"cryptocurrency-wallet\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all cryptocurrency-wallets referenced in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe cryptocurrency-wallets.\n",
    "                    To describe a cryptocurrency-wallet you should provide the fields id, type and value.\n",
    "                    Instead of using UUID in the id field, use the rule type--value for generating ids.\n",
    "                    If no cryptocurrency-wallet are identified return a json with an empty list \"objects\".\n",
    "                    Identify all cryptocurrency-wallet in the folowing CTI report: \"\"\",\n",
    "\n",
    "    \"indicator\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all indicators referenced or implied in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe indicators.\n",
    "                    To describe an indicator you should provide the fields id, type, name, description: Optional, indicator_types: Optional[list], pattern: str, pattern_type: Literal[\"stix\", \"snort\", \"yara\"].\n",
    "                    Instead of using UUID in the id field, use the rule type--name for generating ids.\n",
    "                    If no indicators are identified return a json with an empty list \"objects\".\n",
    "                    Identify all indicators in the folowing CTI report: \"\"\", \n",
    "\n",
    "    \"file\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all files referenced in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe files.\n",
    "                    To describe a file you should provide the fields id, type, name[Optional], hashes: dict, size[Optional], mime_type[Optional].\n",
    "                    Instead of using UUID in the id field, use the rule type--hashes for generating ids.\n",
    "                    If no files are identified return a json with an empty list \"objects\".\n",
    "                    Identify all files in the folowing CTI report: \"\"\",  \n",
    "\n",
    "    \"attack-pattern\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all attack-patterns referenced or implied in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe attack-patterns.\n",
    "                    To describe an attack-pattern you should provide the fields id, type, name, description[Optional], aliases[Optional].\n",
    "                    Instead of using UUID in the id field, use the rule type--name for generating ids.\n",
    "                    If no attack-patterns are identified return a json with an empty list \"objects\".\n",
    "                    Identify all attack-patterns in the folowing CTI report: \"\"\", \n",
    "\n",
    "    \"identity\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all identities referenced in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe identities.\n",
    "                    To describe an identity you should provide the fields id, type, name, description[Optional].\n",
    "                    Instead of using UUID in the id field, use the rule type--name for generating ids.\n",
    "                    If no identities are identified return a json with an empty list \"objects\".\n",
    "                    Identify all identities in the folowing CTI report: \"\"\", \n",
    "\n",
    "    \"malware\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all malwares referenced or implied in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe malwares.\n",
    "                    To describe a malware you should provide the fields id, type, name, description[Optional], malware_types[Optional], is_family[Optional], aliases[Optional], os_execution_envs[Optional], architecture_execution_envs[Optional], implementation_languages[Optional].\n",
    "                    Instead of using UUID in the id field, use the rule type--name for generating ids.\n",
    "                    If no malwares are identified return a json with an empty list \"objects\".\n",
    "                    Identify all malwares in the folowing CTI report: \"\"\", \n",
    "\n",
    "    \"location\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all locations referenced or implied in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe locations.\n",
    "                    To describe a location you should provide the fields id, type, name, country, description[Optional], latitude[Optional], longtitude[Optional], city[Optional].\n",
    "                    Instead of using UUID in the id field, use the rule type--name for generating ids.\n",
    "                    If no locations are identified return a json with an empty list \"objects\".\n",
    "                    Identify all locations in the folowing CTI report: \"\"\", \n",
    "\n",
    "    \"vulnerability\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all vulnerabilities referenced or implied in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe vulnerabilities.\n",
    "                    To describe a vulnerability you should provide the fields id, type, name, description[Optional].\n",
    "                    Instead of using UUID in the id field, use the rule type--name for generating ids.\n",
    "                    If no vulnerabilities are identified return a json with an empty list \"objects\".\n",
    "                    Identify all vulnerabilities in the folowing CTI report: \"\"\",\n",
    "\n",
    "    \"intrusion-set\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all intrusion-sets referenced or implied in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe intrusion-sets.\n",
    "                    To describe an intrusion-set you should provide the fields id, type, name, description[Optional], aliases[Optional], goals[Optional], resource_level[Optional], primary_motivation[Optional], secondary_motivation[Optional].\n",
    "                    Instead of using UUID in the id field, use the rule type--name for generating ids.\n",
    "                    If no intrusion-sets are identified return a json with an empty list \"objects\".\n",
    "                    Identify all intrusion-sets in the folowing CTI report: \"\"\",\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230acb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.6.8: Fast Llama patching. Transformers: 4.53.0. vLLM: 0.9.1.\n",
      "   \\\\   /|    NVIDIA H100 PCIe. Num GPUs = 1. Max memory: 79.179 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 9.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a9bc17438246da97b15310e479be4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "\n",
    "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "#     **config[\"model_loading_args\"]\n",
    "# )\n",
    "\n",
    "#model, tokenizer = customize_tokenizer(model, tokenizer, config)\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    fast_inference = False,\n",
    "    load_in_4bit = False,\n",
    "    max_seq_length = None,\n",
    "    gpu_memory_utilization = 0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bb88b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "FastLanguageModel.for_inference(model)\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "def format_input_prompt(system_message, user_input):\n",
    "    formatted_input = [\n",
    "        {\"role\": \"assistant\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "    return formatted_input\n",
    "\n",
    "def format_validation_example_for_inference(example):\n",
    "    return example.split(\"<|start_header_id|>user<|end_header_id|>\")[1].split(\"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\")[0]\n",
    "\n",
    "def inference(model, system_message, user_input, max_new_tokens=None, **kwargs):\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        format_input_prompt(system_message, user_input),\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors = \"pt\").to(\"cuda\")\n",
    "    if not max_new_tokens:\n",
    "        max_new_tokens = model.config.max_position_embeddings - input_ids.shape[-1]\n",
    "    model.generate(input_ids, streamer = text_streamer, max_new_tokens=max_new_tokens, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5826e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if name in [\"base_model.model.lm_head.modules_to_save.default.weight\", \"base_model.model.model.embed_tokens.modules_to_save.default.weight\"]:\n",
    "#         param.requires_grad = True\n",
    "\n",
    "# total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# print(f'Total number of parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d87667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/mnt/data/openCTI/splitted-io-pairs/train\"\n",
    "validation_path = \"/mnt/data/openCTI/splitted-io-pairs/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cbc35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_train_list = []\n",
    "formatted_eval_list = []\n",
    "include_cti_type = [\"malware\"]\n",
    "\n",
    "for file in os.listdir(train_path):\n",
    "    cti_type = file.split(\"--\")[0]\n",
    "    if cti_type not in include_cti_type:#if cti_type in [\"relationship\", \"report\"]:\n",
    "        continue\n",
    "    example = load_json(train_path, file)\n",
    "    formatted_example = format_example(example, system_messages[cti_type])\n",
    "    formatted_train_list.append(formatted_example)\n",
    "\n",
    "for file in os.listdir(validation_path):\n",
    "    cti_type = file.split(\"--\")[0]\n",
    "    if cti_type not in include_cti_type:#if cti_type in [\"relationship\", \"report\"]:\n",
    "        continue\n",
    "    example = load_json(validation_path, file)\n",
    "    formatted_example = format_example(example, system_messages[cti_type])\n",
    "    formatted_eval_list.append(formatted_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b019d1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted_train_list = formatted_train_list[:5]\n",
    "# formatted_eval_list = formatted_eval_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e336b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f8854bf8094fb289cba46dcbf1056a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/1858 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1006e7938746018fdf9a30323c97a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# Add template of the model in examples\n",
    "templated_train_list = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in formatted_train_list]\n",
    "templated_eval_list = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in formatted_eval_list]\n",
    "# Create hf seperated datasets\n",
    "hf_train = datasets.Dataset.from_list([dict(text=ex) for ex in templated_train_list])\n",
    "hf_eval = datasets.Dataset.from_list([dict(text=ex) for ex in templated_eval_list])\n",
    "# Create a hf dataset dict\n",
    "dataset = datasets.DatasetDict({\"train\":hf_train, \"eval\":hf_eval})\n",
    "# Filter dataset\n",
    "if config[\"filter_dataset\"]:\n",
    "    if not config[\"filter_threshold\"]:\n",
    "        config[\"filter_threshold\"] = tokenizer.model_max_length\n",
    "    dataset = dataset.filter(lambda x: len(tokenizer.encode(x[\"text\"])) <= config[\"filter_threshold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "046823ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 Jul 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
      "                    Your task is to identify all malwares referenced or implied in a CTI report. \n",
      "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
      "                    that describe malwares.\n",
      "                    To describe a malware you should provide the fields id, type, name, description[Optional], malware_types[Optional], is_family[Optional], aliases[Optional], os_execution_envs[Optional], architecture_execution_envs[Optional], implementation_languages[Optional].\n",
      "                    Instead of using UUID in the id field, use the rule type--name for generating ids.\n",
      "                    If no malwares are identified return a json with an empty list \"objects\".\n",
      "                    Identify all malwares in the folowing CTI report:<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "External reference URL: https://www.fortinet.com/blog/threat-research/new-midgedropper-variant\n",
      "\n",
      "CTI REPORT\n",
      "\n",
      "# New MidgeDropper Variant\n",
      "\n",
      "Affected Platforms: Windows\n",
      "\n",
      "Impacted Users: Windows users\n",
      "\n",
      "Impact: Potential to deploy additional malware for additional purposes\n",
      "\n",
      "Severity Level: Medium\n",
      "\n",
      "One of the most exciting aspects of malware analysis is coming across a family that is new or rare to the reversing community. Determining the function of the malware, who created it, and the reasons behind it become a mystery to solve. The previously unseen dropper variant we recently found, named MidgeDropper, has a complex infection chain that includes code obfuscation and sideloading, making it an interesting use case. Although we couldn’t obtain the final payload, this blog will still explore what makes this dropper tick.\n",
      "\n",
      "## Initial Infection Vector\n",
      "\n",
      "The initial infection vector was not available to FortiGuard Labs at the time of our investigation. However, we strongly suspect it to be a phishing e-mail because we have access to an RAR archive—!PENTING\\_LIST OF OFFICERS.rar—that would have been the likely attachment to an e-mail.\n",
      "\n",
      "## !PENTING\\_LIST OF OFFICERS.rar\n",
      "\n",
      "Two files are in the !PENTING\\_LIST OF OFFICERS.rar archive: “Notice to Work-From-Home groups.pdf” and “062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” (Figure 1).\n",
      "\n",
      "\n",
      "\n",
      "## Notice to Work-From-Home groups.pdf\n",
      "\n",
      "The “Notice to Work-From-Home groups.pdf” file is exactly what it appears to be: a PDF file. It contains an image of an error message that falsely indicates that the PDF document failed to load. It is designed to act as a decoy and shift the recipient’s attention to clicking on and executing the “062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” file. Since file extensions are hidden by default in Windows, it is unlikely that anyone reviewing the contents would see the “.exe” and would instead assume they were opening another PDF file.\n",
      "\n",
      "\n",
      "\n",
      "## 062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe\n",
      "\n",
      "At 6.7MB, the ”062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” file is large by malware delivery standards. This executable primarily functions as a dropper for the following stages of infection.\n",
      "\n",
      "The executable drops the files “Microsoft Office.doc,” “IC.exe,” “power.exe,” and “power.xml”. It also reaches out to “hXXp://185[.]225[.]68[.]37/jay/nl/seAgnt.exe” to pull down the file “seAgnt.exe.”\n",
      "\n",
      "\n",
      "\n",
      "## Microsoft Office.doc\n",
      "\n",
      "This file is dropped and opened from “C:\\Users\\&lt;user&gt;\\AppData\\Local\\Temp\\Microsoft\\Office.” It is also meant to be a decoy. It is populated in some versions of the dropper, but it was empty and benign in the version analyzed by FortiGuard Labs.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## IC.exe\n",
      "\n",
      "“IC.exe” is dropped by “062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” and deposited into “C:\\ProgramData\\Emisoft\\Microsoft\\Stream\\IC.exe.” It is responsible for obtaining the next stage of the infection.\n",
      "\n",
      "\n",
      "\n",
      "“IC.exe” reaches out to a URL at “185[.]225[.]68[.]37” to download an additional file, “VCRUNTIME140\\_1.dll.”\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "As can probably be guessed by the filename, “VCRUNTIME140\\_1.dll” is meant to appear as a file related to the Microsoft Visual C++ Redistributable Package.\n",
      "\n",
      "## power.exe and power.xml\n",
      "\n",
      "“power.exe” is dropped along with “power.xml” by ”062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe”.  “power.exe” only has one job: decoding and processing “power.xml.”\n",
      "\n",
      "\n",
      "\n",
      "Figure 9 shows that “power.xml” in its native format is obfuscated and not readily readable.  This can be easily rectified by removing the garbage characters used for obfuscation.\n",
      "\n",
      "\n",
      "\n",
      "With obfuscation removed, an XML document remains. Much of the information is irrelevant except for the final section under the “Actions” tag. The primary purpose of this pair of files is to launch “seAgnt.exe.”\n",
      "\n",
      "## seAgnt.exe\n",
      "\n",
      "“seAgnt.exe” is a renamed copy of “GameBarFTServer.exe,” which is an application published by Microsoft, “Xbox Game Bar Full Trust COM Server.”  It is a background process for the Xbox Game Bar that runs on Windows.\n",
      "\n",
      "\n",
      "\n",
      "Although itself benign, “seAgnt.exe” does depend on “VCRUNTIME140\\_1.dll”.  This dependency allows the malicious code inside of the DLL to execute.\n",
      "\n",
      "\n",
      "\n",
      "## VCRUNTIME140\\_1.dll\n",
      "\n",
      "“VCRUNTIME140\\_1.dll” is a legitimate DLL that is part of the Microsoft Visual C++ runtime package. Unfortunately, the particular version used here is malicious.\n",
      "\n",
      "Due to “VCRUNTIME140\\_1.dll” being a Dynamic Link Library, it doesn’t exist as a separate executable. It has to have assistance via another application to load its code into memory and execute it. “seAgnt.exe” is that application. This technique is called sideloading (https://attack.mitre.org/techniques/T1574/002/) because a dependency of a legitimate application is highjacked to allow the malicious code to load.\n",
      "\n",
      "\n",
      "\n",
      "The file is heavily obfuscated and designed to make analysis much more difficult. For example, the figure below shows the massive number of function jumps that attempt to hide the purpose of the code.\n",
      "\n",
      "\n",
      "\n",
      "The rest of the code makes it equally difficult to follow along in a disassembler.\n",
      "\n",
      "The primary purpose of the code appears to be reaching out to “hXXp://185[.]225[.]68[.]37/jay/nl/35g3498734gkb.dat” to pull down the file “35g3498734gkb.dat”.\n",
      "\n",
      "\n",
      "\n",
      "## 35g3498734gkb.dat\n",
      "\n",
      "Oddly, “35g3498734gkb.dat” is identical to “VCRUNTIME140\\_1.dll” in terms of the file hash, so it’s unclear why the threat actor opted to pull it down again from the C2 node.\n",
      "\n",
      "\n",
      "\n",
      "Unfortunately, further links on the infection chain were taken down when our analysis began, preventing further analysis of any potential final payloads.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Despite the final payload being unavailable before FortiGuard Labs could analyze it, this dropper made an interesting case study and provided a subject to watch out for.\n",
      "\n",
      "## Fortinet Protections\n",
      "\n",
      "Fortinet customers are already protected from this malware through FortiGuard’s Web Filtering, AntiVirus, FortiMail, FortiClient, and FortiEDR services, as follows:\n",
      "\n",
      "The following (AV) signature detects the malware samples mentioned in this blog\n",
      "\n",
      "- MalwThreat!caa0FT\n",
      "- W32/Agent.9CDF!tr\n",
      "\n",
      "The WebFiltering client blocks all network-based URIs.\n",
      "\n",
      "Fortinet has multiple solutions designed to help train users to understand and detect phishing threats:\n",
      "\n",
      "The FortiPhish Phishing Simulation Service uses real-world simulations to help organizations test user awareness and vigilance to phishing threats and to train and reinforce proper practices when users encounter targeted phishing attacks.\n",
      "\n",
      "We also suggest that organizations have their end users undergo our FREE NSE training: NSE 1 – Information Security Awareness. It includes a module on Internet threats designed to help end users learn how to identify and protect themselves from various types of phishing attacks.\n",
      "\n",
      "If you think this or any other cybersecurity threat has impacted your organization, contact our Global FortiGuard Incident Response Team.\n",
      "\n",
      "## IOCs\n",
      "\n",
      "### File-based IOCs:\n",
      "\n",
      "| Filename                                                                      | SHA256                                                           |\n",
      "|-------------------------------------------------------------------------------|------------------------------------------------------------------|\n",
      "| !PENTING_LIST OF OFFICERS.rar                                                 | 2dcf00b0f6c41c2c60561ca92893a0a9bf060e1d46af426de022d0c5d23d8704 |\n",
      "| Notice to Work-From-Home groups.pdf                                           | 30417ca261eefe40f7c44ff956f9940b766ae9a0c574cd1c06a4b545e46f692e |\n",
      "| 062023_PENTING_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe | c22cc7111191e5a1a2010f4bc3127058bff41ecba8d753378feabee37d5b43bb |\n",
      "| Microsoft Office.doc                                                          | 59334a6e2c5faabe3a1baf5347ba01f2419d731fcbb7ab1b021185c059c8fa6f |\n",
      "| IC.exe                                                                        | fc40e782731b8d3b9ec5e5cf8a9d8b8126dc05028ca58ec52db155b3dadc5fc6 |\n",
      "| power.exe                                                                     | f26f5a52bddda5eb3245161b784b58635ffa2381818816e50b8bae9680ff88eb |\n",
      "| power.xml                                                                     | f43cca8d2e996ee78edf8d9e64e05f35e94a730fbe51e9feecc5e364280d8534 |\n",
      "| seAgnt.exe                                                                    | b3e0388f215ac127b647cd7d3f186f2f666dc0535d66797b6e1adb74f828254e |\n",
      "| VCRUNTIME140_1.dll / 35g3498734gkb.dat                                        | 527afa0c415af005594acaac1093a1ea79e3639fa5563602497eabbae7438130 |\n",
      "\n",
      "### Network-based IOCs:\n",
      "\n",
      "| IOC                                                  | IOC type                |\n",
      "|------------------------------------------------------|-------------------------|\n",
      "| 185[.]225[.]69[.]226                                 | C2 Node                 |\n",
      "| hXXp://185[.]225[.]68[.]37/jay/nl/VCRUNTIME140_1.dll | Stage download location |\n",
      "| hXXp://185[.]225[.]68[.]37/jay/nl/seAgnt.exe         | Stage download location |\n",
      "| hXXp://185[.]225[.]68[.]37/jay/nl/35g3498734gkb.dat  | Stage download location |\n",
      "\n",
      "### Related Posts\n",
      "\n",
      "\n",
      "\n",
      "FortiGuard Labs Threat Research\n",
      "\n",
      "##### Ransomware Roundup - Rhysida\n",
      "\n",
      "\n",
      "\n",
      "FortiGuard Labs Threat Research\n",
      "\n",
      "##### Ransomware Roundup – Trash Panda and A New Minor Variant of NoCry\n",
      "\n",
      "\n",
      "\n",
      "FortiGuard Labs Threat Research\n",
      "\n",
      "##### Ransomware Roundup - DoDo and Proton\n",
      "\n",
      "\n",
      "\n",
      "#### News &amp; Articles\n",
      "\n",
      "- News Releases\n",
      "- News Articles\n",
      "\n",
      "#### Security Research\n",
      "\n",
      "- Threat Research\n",
      "- FortiGuard Labs\n",
      "- Threat Map\n",
      "- Ransomware Prevention\n",
      "\n",
      "#### Connect With Us\n",
      "\n",
      "- Fortinet Community\n",
      "- Partner Portal\n",
      "- Investor Relations\n",
      "- Product Certifications\n",
      "\n",
      "#### Company\n",
      "\n",
      "- About Us\n",
      "- Exec Mgmt\n",
      "- Careers\n",
      "- Training\n",
      "- Events\n",
      "- Industry Awards\n",
      "- Social Responsibility\n",
      "- CyberGlossary\n",
      "- Sitemap\n",
      "- Blog Sitemap\n",
      "\n",
      "#### Contact Us\n",
      "\n",
      "- (866) 868-3678\n",
      "\n",
      "Copyright © 2025 Fortinet, Inc. All Rights Reserved\n",
      "\n",
      "Also of Interest:\n",
      "\n",
      "- Progress against vulnerabilities\n",
      "- Network Security Vulnerabilities\n",
      "- FortiGuard Labs Threat Research\n",
      "- Pay Ransomware Settlements?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "########################################################################################################################################################################################################\n",
      "\n",
      "\n",
      "External reference URL: https://otx.alienvault.com/pulse/650815eae6309eba75a1d6a2\n",
      "\n",
      "CTI REPORT\n",
      "\n",
      "# Title #\n",
      "New MidgeDropper Variant\n",
      "\n",
      "# Metadata #\n",
      "Created 2 years ago by AlienVault Public TLP:  White\n",
      "\n",
      "# Contents #\n",
      "Tags: MidgeDropper, Obfuscation, phishing, RAR archive\n",
      "\n",
      "Group:  2MISP\n",
      "\n",
      "Malware Family: MidgeDropper\n",
      "\n",
      "Att&ck IDs: T1566 - Phishing ,  T1001 - Data Obfuscation ,  T1027 - Obfuscated Files or Information ,  T1083 - File and Directory Discovery ,  T1071 - Application Layer Protocol ,  T1073 - DLL Side-Loading\n",
      "\n",
      "# Indicators of Compromise #\n",
      "           type                                                        indicator Role title                    Added Active related Pulses\n",
      "FileHash-SHA256 2dcf00b0f6c41c2c60561ca92893a0a9bf060e1d46af426de022d0c5d23d8704            Sep 18, 2023, 9:18:35 AM                     6\n",
      "FileHash-SHA256 30417ca261eefe40f7c44ff956f9940b766ae9a0c574cd1c06a4b545e46f692e            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 527afa0c415af005594acaac1093a1ea79e3639fa5563602497eabbae7438130            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 59334a6e2c5faabe3a1baf5347ba01f2419d731fcbb7ab1b021185c059c8fa6f            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 b3e0388f215ac127b647cd7d3f186f2f666dc0535d66797b6e1adb74f828254e            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 c22cc7111191e5a1a2010f4bc3127058bff41ecba8d753378feabee37d5b43bb            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 f26f5a52bddda5eb3245161b784b58635ffa2381818816e50b8bae9680ff88eb            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 f43cca8d2e996ee78edf8d9e64e05f35e94a730fbe51e9feecc5e364280d8534            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 fc40e782731b8d3b9ec5e5cf8a9d8b8126dc05028ca58ec52db155b3dadc5fc6            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                                     http://185.225.68.37/jay/nl/            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                    http://185.225.68.37/jay/nl/35g3498734gkb.dat            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL           http://185.225.68.37/jay/nl/35g3498734gkb.xn--dat-9o0a            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                   http://185.225.68.37/jay/nl/VCRUNTIME140_1.dll            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                           http://185.225.68.37/jay/nl/seAgnt.exe            Sep 18, 2023, 9:18:35 AM                     5<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{\"objects\": [{\"id\": \"malware--MidgeDropper\", \"type\": \"malware\", \"name\": \"MidgeDropper\", \"is_family\": false}]}<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb5cb64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "External reference URL: https://www.fortinet.com/blog/threat-research/new-midgedropper-variant\n",
      "\n",
      "CTI REPORT\n",
      "\n",
      "# New MidgeDropper Variant\n",
      "\n",
      "Affected Platforms: Windows\n",
      "\n",
      "Impacted Users: Windows users\n",
      "\n",
      "Impact: Potential to deploy additional malware for additional purposes\n",
      "\n",
      "Severity Level: Medium\n",
      "\n",
      "One of the most exciting aspects of malware analysis is coming across a family that is new or rare to the reversing community. Determining the function of the malware, who created it, and the reasons behind it become a mystery to solve. The previously unseen dropper variant we recently found, named MidgeDropper, has a complex infection chain that includes code obfuscation and sideloading, making it an interesting use case. Although we couldn’t obtain the final payload, this blog will still explore what makes this dropper tick.\n",
      "\n",
      "## Initial Infection Vector\n",
      "\n",
      "The initial infection vector was not available to FortiGuard Labs at the time of our investigation. However, we strongly suspect it to be a phishing e-mail because we have access to an RAR archive—!PENTING\\_LIST OF OFFICERS.rar—that would have been the likely attachment to an e-mail.\n",
      "\n",
      "## !PENTING\\_LIST OF OFFICERS.rar\n",
      "\n",
      "Two files are in the !PENTING\\_LIST OF OFFICERS.rar archive: “Notice to Work-From-Home groups.pdf” and “062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” (Figure 1).\n",
      "\n",
      "\n",
      "\n",
      "## Notice to Work-From-Home groups.pdf\n",
      "\n",
      "The “Notice to Work-From-Home groups.pdf” file is exactly what it appears to be: a PDF file. It contains an image of an error message that falsely indicates that the PDF document failed to load. It is designed to act as a decoy and shift the recipient’s attention to clicking on and executing the “062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” file. Since file extensions are hidden by default in Windows, it is unlikely that anyone reviewing the contents would see the “.exe” and would instead assume they were opening another PDF file.\n",
      "\n",
      "\n",
      "\n",
      "## 062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe\n",
      "\n",
      "At 6.7MB, the ”062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” file is large by malware delivery standards. This executable primarily functions as a dropper for the following stages of infection.\n",
      "\n",
      "The executable drops the files “Microsoft Office.doc,” “IC.exe,” “power.exe,” and “power.xml”. It also reaches out to “hXXp://185[.]225[.]68[.]37/jay/nl/seAgnt.exe” to pull down the file “seAgnt.exe.”\n",
      "\n",
      "\n",
      "\n",
      "## Microsoft Office.doc\n",
      "\n",
      "This file is dropped and opened from “C:\\Users\\&lt;user&gt;\\AppData\\Local\\Temp\\Microsoft\\Office.” It is also meant to be a decoy. It is populated in some versions of the dropper, but it was empty and benign in the version analyzed by FortiGuard Labs.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## IC.exe\n",
      "\n",
      "“IC.exe” is dropped by “062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” and deposited into “C:\\ProgramData\\Emisoft\\Microsoft\\Stream\\IC.exe.” It is responsible for obtaining the next stage of the infection.\n",
      "\n",
      "\n",
      "\n",
      "“IC.exe” reaches out to a URL at “185[.]225[.]68[.]37” to download an additional file, “VCRUNTIME140\\_1.dll.”\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "As can probably be guessed by the filename, “VCRUNTIME140\\_1.dll” is meant to appear as a file related to the Microsoft Visual C++ Redistributable Package.\n",
      "\n",
      "## power.exe and power.xml\n",
      "\n",
      "“power.exe” is dropped along with “power.xml” by ”062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe”.  “power.exe” only has one job: decoding and processing “power.xml.”\n",
      "\n",
      "\n",
      "\n",
      "Figure 9 shows that “power.xml” in its native format is obfuscated and not readily readable.  This can be easily rectified by removing the garbage characters used for obfuscation.\n",
      "\n",
      "\n",
      "\n",
      "With obfuscation removed, an XML document remains. Much of the information is irrelevant except for the final section under the “Actions” tag. The primary purpose of this pair of files is to launch “seAgnt.exe.”\n",
      "\n",
      "## seAgnt.exe\n",
      "\n",
      "“seAgnt.exe” is a renamed copy of “GameBarFTServer.exe,” which is an application published by Microsoft, “Xbox Game Bar Full Trust COM Server.”  It is a background process for the Xbox Game Bar that runs on Windows.\n",
      "\n",
      "\n",
      "\n",
      "Although itself benign, “seAgnt.exe” does depend on “VCRUNTIME140\\_1.dll”.  This dependency allows the malicious code inside of the DLL to execute.\n",
      "\n",
      "\n",
      "\n",
      "## VCRUNTIME140\\_1.dll\n",
      "\n",
      "“VCRUNTIME140\\_1.dll” is a legitimate DLL that is part of the Microsoft Visual C++ runtime package. Unfortunately, the particular version used here is malicious.\n",
      "\n",
      "Due to “VCRUNTIME140\\_1.dll” being a Dynamic Link Library, it doesn’t exist as a separate executable. It has to have assistance via another application to load its code into memory and execute it. “seAgnt.exe” is that application. This technique is called sideloading (https://attack.mitre.org/techniques/T1574/002/) because a dependency of a legitimate application is highjacked to allow the malicious code to load.\n",
      "\n",
      "\n",
      "\n",
      "The file is heavily obfuscated and designed to make analysis much more difficult. For example, the figure below shows the massive number of function jumps that attempt to hide the purpose of the code.\n",
      "\n",
      "\n",
      "\n",
      "The rest of the code makes it equally difficult to follow along in a disassembler.\n",
      "\n",
      "The primary purpose of the code appears to be reaching out to “hXXp://185[.]225[.]68[.]37/jay/nl/35g3498734gkb.dat” to pull down the file “35g3498734gkb.dat”.\n",
      "\n",
      "\n",
      "\n",
      "## 35g3498734gkb.dat\n",
      "\n",
      "Oddly, “35g3498734gkb.dat” is identical to “VCRUNTIME140\\_1.dll” in terms of the file hash, so it’s unclear why the threat actor opted to pull it down again from the C2 node.\n",
      "\n",
      "\n",
      "\n",
      "Unfortunately, further links on the infection chain were taken down when our analysis began, preventing further analysis of any potential final payloads.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Despite the final payload being unavailable before FortiGuard Labs could analyze it, this dropper made an interesting case study and provided a subject to watch out for.\n",
      "\n",
      "## Fortinet Protections\n",
      "\n",
      "Fortinet customers are already protected from this malware through FortiGuard’s Web Filtering, AntiVirus, FortiMail, FortiClient, and FortiEDR services, as follows:\n",
      "\n",
      "The following (AV) signature detects the malware samples mentioned in this blog\n",
      "\n",
      "- MalwThreat!caa0FT\n",
      "- W32/Agent.9CDF!tr\n",
      "\n",
      "The WebFiltering client blocks all network-based URIs.\n",
      "\n",
      "Fortinet has multiple solutions designed to help train users to understand and detect phishing threats:\n",
      "\n",
      "The FortiPhish Phishing Simulation Service uses real-world simulations to help organizations test user awareness and vigilance to phishing threats and to train and reinforce proper practices when users encounter targeted phishing attacks.\n",
      "\n",
      "We also suggest that organizations have their end users undergo our FREE NSE training: NSE 1 – Information Security Awareness. It includes a module on Internet threats designed to help end users learn how to identify and protect themselves from various types of phishing attacks.\n",
      "\n",
      "If you think this or any other cybersecurity threat has impacted your organization, contact our Global FortiGuard Incident Response Team.\n",
      "\n",
      "## IOCs\n",
      "\n",
      "### File-based IOCs:\n",
      "\n",
      "| Filename                                                                      | SHA256                                                           |\n",
      "|-------------------------------------------------------------------------------|------------------------------------------------------------------|\n",
      "| !PENTING_LIST OF OFFICERS.rar                                                 | 2dcf00b0f6c41c2c60561ca92893a0a9bf060e1d46af426de022d0c5d23d8704 |\n",
      "| Notice to Work-From-Home groups.pdf                                           | 30417ca261eefe40f7c44ff956f9940b766ae9a0c574cd1c06a4b545e46f692e |\n",
      "| 062023_PENTING_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe | c22cc7111191e5a1a2010f4bc3127058bff41ecba8d753378feabee37d5b43bb |\n",
      "| Microsoft Office.doc                                                          | 59334a6e2c5faabe3a1baf5347ba01f2419d731fcbb7ab1b021185c059c8fa6f |\n",
      "| IC.exe                                                                        | fc40e782731b8d3b9ec5e5cf8a9d8b8126dc05028ca58ec52db155b3dadc5fc6 |\n",
      "| power.exe                                                                     | f26f5a52bddda5eb3245161b784b58635ffa2381818816e50b8bae9680ff88eb |\n",
      "| power.xml                                                                     | f43cca8d2e996ee78edf8d9e64e05f35e94a730fbe51e9feecc5e364280d8534 |\n",
      "| seAgnt.exe                                                                    | b3e0388f215ac127b647cd7d3f186f2f666dc0535d66797b6e1adb74f828254e |\n",
      "| VCRUNTIME140_1.dll / 35g3498734gkb.dat                                        | 527afa0c415af005594acaac1093a1ea79e3639fa5563602497eabbae7438130 |\n",
      "\n",
      "### Network-based IOCs:\n",
      "\n",
      "| IOC                                                  | IOC type                |\n",
      "|------------------------------------------------------|-------------------------|\n",
      "| 185[.]225[.]69[.]226                                 | C2 Node                 |\n",
      "| hXXp://185[.]225[.]68[.]37/jay/nl/VCRUNTIME140_1.dll | Stage download location |\n",
      "| hXXp://185[.]225[.]68[.]37/jay/nl/seAgnt.exe         | Stage download location |\n",
      "| hXXp://185[.]225[.]68[.]37/jay/nl/35g3498734gkb.dat  | Stage download location |\n",
      "\n",
      "### Related Posts\n",
      "\n",
      "\n",
      "\n",
      "FortiGuard Labs Threat Research\n",
      "\n",
      "##### Ransomware Roundup - Rhysida\n",
      "\n",
      "\n",
      "\n",
      "FortiGuard Labs Threat Research\n",
      "\n",
      "##### Ransomware Roundup – Trash Panda and A New Minor Variant of NoCry\n",
      "\n",
      "\n",
      "\n",
      "FortiGuard Labs Threat Research\n",
      "\n",
      "##### Ransomware Roundup - DoDo and Proton\n",
      "\n",
      "\n",
      "\n",
      "#### News &amp; Articles\n",
      "\n",
      "- News Releases\n",
      "- News Articles\n",
      "\n",
      "#### Security Research\n",
      "\n",
      "- Threat Research\n",
      "- FortiGuard Labs\n",
      "- Threat Map\n",
      "- Ransomware Prevention\n",
      "\n",
      "#### Connect With Us\n",
      "\n",
      "- Fortinet Community\n",
      "- Partner Portal\n",
      "- Investor Relations\n",
      "- Product Certifications\n",
      "\n",
      "#### Company\n",
      "\n",
      "- About Us\n",
      "- Exec Mgmt\n",
      "- Careers\n",
      "- Training\n",
      "- Events\n",
      "- Industry Awards\n",
      "- Social Responsibility\n",
      "- CyberGlossary\n",
      "- Sitemap\n",
      "- Blog Sitemap\n",
      "\n",
      "#### Contact Us\n",
      "\n",
      "- (866) 868-3678\n",
      "\n",
      "Copyright © 2025 Fortinet, Inc. All Rights Reserved\n",
      "\n",
      "Also of Interest:\n",
      "\n",
      "- Progress against vulnerabilities\n",
      "- Network Security Vulnerabilities\n",
      "- FortiGuard Labs Threat Research\n",
      "- Pay Ransomware Settlements?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "########################################################################################################################################################################################################\n",
      "\n",
      "\n",
      "External reference URL: https://otx.alienvault.com/pulse/650815eae6309eba75a1d6a2\n",
      "\n",
      "CTI REPORT\n",
      "\n",
      "# Title #\n",
      "New MidgeDropper Variant\n",
      "\n",
      "# Metadata #\n",
      "Created 2 years ago by AlienVault Public TLP:  White\n",
      "\n",
      "# Contents #\n",
      "Tags: MidgeDropper, Obfuscation, phishing, RAR archive\n",
      "\n",
      "Group:  2MISP\n",
      "\n",
      "Malware Family: MidgeDropper\n",
      "\n",
      "Att&ck IDs: T1566 - Phishing ,  T1001 - Data Obfuscation ,  T1027 - Obfuscated Files or Information ,  T1083 - File and Directory Discovery ,  T1071 - Application Layer Protocol ,  T1073 - DLL Side-Loading\n",
      "\n",
      "# Indicators of Compromise #\n",
      "           type                                                        indicator Role title                    Added Active related Pulses\n",
      "FileHash-SHA256 2dcf00b0f6c41c2c60561ca92893a0a9bf060e1d46af426de022d0c5d23d8704            Sep 18, 2023, 9:18:35 AM                     6\n",
      "FileHash-SHA256 30417ca261eefe40f7c44ff956f9940b766ae9a0c574cd1c06a4b545e46f692e            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 527afa0c415af005594acaac1093a1ea79e3639fa5563602497eabbae7438130            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 59334a6e2c5faabe3a1baf5347ba01f2419d731fcbb7ab1b021185c059c8fa6f            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 b3e0388f215ac127b647cd7d3f186f2f666dc0535d66797b6e1adb74f828254e            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 c22cc7111191e5a1a2010f4bc3127058bff41ecba8d753378feabee37d5b43bb            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 f26f5a52bddda5eb3245161b784b58635ffa2381818816e50b8bae9680ff88eb            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 f43cca8d2e996ee78edf8d9e64e05f35e94a730fbe51e9feecc5e364280d8534            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 fc40e782731b8d3b9ec5e5cf8a9d8b8126dc05028ca58ec52db155b3dadc5fc6            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                                     http://185.225.68.37/jay/nl/            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                    http://185.225.68.37/jay/nl/35g3498734gkb.dat            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL           http://185.225.68.37/jay/nl/35g3498734gkb.xn--dat-9o0a            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                   http://185.225.68.37/jay/nl/VCRUNTIME140_1.dll            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                           http://185.225.68.37/jay/nl/seAgnt.exe            Sep 18, 2023, 9:18:35 AM                     5\n"
     ]
    }
   ],
   "source": [
    "print(format_validation_example_for_inference(dataset[\"train\"][\"text\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c4061a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "LlamaForCausalLM has no `_prepare_4d_causal_attention_mask_with_cache_position` method defined in its base modeling class. Compiled forward passes will be sub-optimal. If you're writing code, see Llama for an example implementation. If you're a user, please report this issue on GitHub.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the JSON response with the identified malwares:\n",
      "```\n",
      "{\n",
      "    \"objects\": [\n",
      "        {\n",
      "            \"id\": \"midge_dropper\",\n",
      "            \"type\": \"malware\",\n",
      "            'name': 'MidgeDroppper',\n",
      "            \"description\": \"A complex dropper malware with a multi-stage infection chain.\",\n",
      "            \"malwares_types\": [\"dropper\"],\n",
      "            \"is_family\": true,\n",
      "            \"aliases\": [\"Obfuscation\", \"phishing\", \"RAR archive\"],\n",
      "            'os_execution_env': ['Windows'],\n",
      "            'architecture_execution_env' :['x86'],\n",
      "            \"implementation_languages\": [\"unknown\"],\n",
      "            \"_created\": \"2 years\"\n",
      "        },\n",
      "        {\n",
      "          \"id\":\"vcruntime140_\",\n",
      "          \"type\":\"dll\",\n",
      "          'name':'VCRUNTIme140_',\n",
      "          \"description\":\"\",\n",
      "          \"malworms_types\": [],\n",
      "          \"is_familly\": false,\n",
      "          \"aliases\":[\"VCRRUNTIME140.dll\"],\n",
      "          'os_exection_env':['Windows'],\n",
      "          'architecture_exection_enve' :[\"x86\"],\n",
      "          \"implementation_language\": [\"C\"]\n",
      "        },\n",
      "       {\n",
      "          'id':\"seagnt\",\n",
      "          type:'exe',\n",
      "          'Name':'SeAgnt',\n",
      "          description:'',\n",
      "          malware_type':['dropper'],\n",
      "          \"family\":false,\n",
      "          'aliases':['seAgent'],\n",
      "          '_os_execution_environment':['windows'],\n",
      "          \"_architecture_execution_environment\":['x64'],\n",
      "          _implementation_language:['c']\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "system_message = system_messages[\"malware\"]\n",
    "user_input = format_validation_example_for_inference(dataset[\"train\"][\"text\"][0])\n",
    "inference(model,\n",
    "          system_message, \n",
    "          user_input, \n",
    "          max_new_tokens=None,\n",
    "          temperature=0.7,\n",
    "          top_p=0.6,\n",
    "          repetition_penalty=1.1,\n",
    "          no_repeat_ngram_size=3,\n",
    "          do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "889cf9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias': 'none',\n",
      " 'loftq_config': 'None',\n",
      " 'lora_alpha': 32,\n",
      " 'lora_dropout': 0,\n",
      " 'r': 32,\n",
      " 'target_modules': ['q_proj',\n",
      "                    'k_proj',\n",
      "                    'v_proj',\n",
      "                    'o_proj',\n",
      "                    'gate_proj',\n",
      "                    'up_proj',\n",
      "                    'down_proj',\n",
      "                    'lm_head',\n",
      "                    'embed_tokens'],\n",
      " 'use_gradient_checkpointing': 'unsloth',\n",
      " 'use_rslora': True}\n"
     ]
    }
   ],
   "source": [
    "config[\"lora_parameters\"][\"r\"] = 32\n",
    "config[\"lora_parameters\"][\"lora_alpha\"] = 32\n",
    "pprint(config[\"lora_parameters\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e301342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Offloading input_embeddings to disk to save VRAM\n",
      "Unsloth: Offloading output_embeddings to disk to save VRAM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.6.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Training embed_tokens in mixed precision to save VRAM\n",
      "Unsloth: Training lm_head in mixed precision to save VRAM\n"
     ]
    }
   ],
   "source": [
    "# Add LoRA weights\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model=model,\n",
    "    **config[\"lora_parameters\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6ac39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_on_responses_only_bool = True\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a12b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"training_arguments\"][\"output_dir\"] = \"Llama-3.1-8B-Malware-Expert\"\n",
    "config[\"training_arguments\"][\"seed\"] = 4321\n",
    "config[\"lr_scheduler_type\"] = \"cosine\" #constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea9339ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc439ec17424882b5a22e4b4359ba77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/1858 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8c31becf314c13b45db5939cd89b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"]:   0%|          | 0/301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initiate trainer\n",
    "trainer = UnslothTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset[\"train\"],\n",
    "    eval_dataset = dataset[\"eval\"],\n",
    "    data_collator = data_collator,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = config[\"model_loading_args\"][\"max_seq_length\"], # Used only when packing=True for creating a ConstantLengthDataset.\n",
    "    packing = config[\"sft_trainer_arguments\"][\"apply_packing\"],\n",
    "    dataset_num_proc = num_proc,\n",
    "    args = UnslothTrainingArguments(\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        **config[\"training_arguments\"]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63436d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69228dc845ae47019ca2e06923b71f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/1858 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca524ab47b54a0592b58ce8da6b4e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=30):   0%|          | 0/301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wrap trainer for apply training using only the assistant part\n",
    "if _train_on_responses_only_bool:\n",
    "    trainer = train_on_responses_only(\n",
    "        trainer,\n",
    "        instruction_part = config[\"instruction_part\"],\n",
    "        response_part = config[\"response_part\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3bd68b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config[\"early_stopping_patience\"] = False\n",
    "\n",
    "if config[\"early_stopping_patience\"]:\n",
    "    from transformers import EarlyStoppingCallback\n",
    "    early_stopping_callback = EarlyStoppingCallback(early_stopping_patience = config[\"early_stopping_patience\"])\n",
    "    trainer.add_callback(early_stopping_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "019a97c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,858 | Num Epochs = 5 | Total steps = 295\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 16\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 16 x 1) = 32\n",
      " \"-____-\"     Trainable parameters = 1,134,559,232/9,164,820,480 (12.38% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Setting lr = 5.00e-06 instead of 5.00e-05 for embed_tokens.\n",
      "Unsloth: Setting lr = 5.00e-06 instead of 5.00e-05 for lm_head.\n",
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='295' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/295 : < :, Epoch 0.02/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='151' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  1/151 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Not an error, but LlamaForCausalLM does not accept `num_items_in_batch`.\n",
      "Using gradient accumulation will be very slightly less accurate.\n",
      "Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 36.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 3.72 GiB is free. Process 2072594 has 15.76 GiB memory in use. Including non-PyTorch memory, this process has 59.64 GiB memory in use. Of the allocated memory 58.73 GiB is allocated by PyTorch, and 190.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m trainer_stats = \u001b[43munsloth_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#, resume_from_checkpoint = True)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/unsloth/trainer.py:45\u001b[39m, in \u001b[36munsloth_train\u001b[39m\u001b[34m(trainer, *args, **kwargs)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34munsloth_train\u001b[39m(trainer, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/transformers/trainer.py:2207\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2205\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2208\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2210\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2211\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2212\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:395\u001b[39m, in \u001b[36m_fast_inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/transformers/trainer.py:3097\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3095\u001b[39m metrics = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_evaluate:\n\u001b[32m-> \u001b[39m\u001b[32m3097\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3098\u001b[39m     is_new_best_metric = \u001b[38;5;28mself\u001b[39m._determine_best_metric(metrics=metrics, trial=trial)\n\u001b[32m   3100\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_strategy == SaveStrategy.BEST:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/transformers/trainer.py:3046\u001b[39m, in \u001b[36mTrainer._evaluate\u001b[39m\u001b[34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[39m\n\u001b[32m   3045\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m3046\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3047\u001b[39m     \u001b[38;5;28mself\u001b[39m._report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m.state.global_step, metrics)\n\u001b[32m   3049\u001b[39m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/transformers/trainer.py:4200\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4197\u001b[39m start_time = time.time()\n\u001b[32m   4199\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m4200\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4201\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4203\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[32m   4204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[32m   4205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4208\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4210\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/transformers/trainer.py:4395\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4392\u001b[39m         batch_size = observed_batch_size\n\u001b[32m   4394\u001b[39m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4395\u001b[39m losses, logits, labels = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4396\u001b[39m main_input_name = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.model, \u001b[33m\"\u001b[39m\u001b[33mmain_input_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4397\u001b[39m inputs_decode = (\n\u001b[32m   4398\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args.include_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4399\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/transformers/trainer.py:4611\u001b[39m, in \u001b[36mTrainer.prediction_step\u001b[39m\u001b[34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[39m\n\u001b[32m   4609\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[32m   4610\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m4611\u001b[39m         loss, outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   4612\u001b[39m     loss = loss.detach().mean()\n\u001b[32m   4614\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/unsloth_compiled_cache/UnslothSFTTrainer.py:884\u001b[39m, in \u001b[36m_UnslothSFTTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, inputs, return_outputs = \u001b[38;5;28;01mFalse\u001b[39;00m, num_items_in_batch = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m884\u001b[39m     outputs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    890\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/unsloth/models/_utils.py:1083\u001b[39m, in \u001b[36m_unsloth_pre_compute_loss\u001b[39m\u001b[34m(self, model, inputs, *args, **kwargs)\u001b[39m\n\u001b[32m   1077\u001b[39m     logger.warning_once(\n\u001b[32m   1078\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsloth: Not an error, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept `num_items_in_batch`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\\\n\u001b[32m   1079\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUsing gradient accumulation will be very slightly less accurate.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\\\n\u001b[32m   1080\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mRead more on gradient accumulation issues here: https://unsloth.ai/blog/gradient\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1081\u001b[39m     )\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1083\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_compute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/transformers/trainer.py:3837\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3835\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3836\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3837\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3838\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3839\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3840\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/accelerate/utils/operations.py:818\u001b[39m, in \u001b[36mconvert_outputs_to_fp32.<locals>.forward\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    817\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/accelerate/utils/operations.py:806\u001b[39m, in \u001b[36mConvertOutputsToFp32.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    805\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m806\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:44\u001b[39m, in \u001b[36mautocast_decorator.<locals>.decorate_autocast\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_autocast\u001b[39m(*args, **kwargs):\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/torch/_compile.py:51\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     49\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:838\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    836\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    840\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/unsloth/models/llama.py:1275\u001b[39m, in \u001b[36mPeftModel_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m   1264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.base_model(\n\u001b[32m   1265\u001b[39m         input_ids = input_ids,\n\u001b[32m   1266\u001b[39m         attention_mask = attention_mask, \n\u001b[32m   (...)\u001b[39m\u001b[32m   1272\u001b[39m         **kwargs,\n\u001b[32m   1273\u001b[39m         )\n\u001b[32m   1274\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1276\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1281\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1282\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1284\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_logits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1285\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1286\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1287\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:193\u001b[39m, in \u001b[36mBaseTuner.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any):\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/unsloth/models/llama.py:1104\u001b[39m, in \u001b[36mCausalLM_fast_forward.<locals>._CausalLM_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[39m\n\u001b[32m   1102\u001b[39m     \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m.model._has_no_labels = labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1113\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1115\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1117\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/unsloth/models/llama.py:925\u001b[39m, in \u001b[36mLlamaModel_fast_forward\u001b[39m\u001b[34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, *args, **kwargs)\u001b[39m\n\u001b[32m    922\u001b[39m     hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m           \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    936\u001b[39m     hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/transformers/modeling_layers.py:83\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m         logger.warning(message)\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/unsloth/models/llama.py:594\u001b[39m, in \u001b[36mLlamaDecoderLayer_fast_forward\u001b[39m\u001b[34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[39m\n\u001b[32m    592\u001b[39m residual = hidden_states\n\u001b[32m    593\u001b[39m hidden_states = fast_rms_layernorm(\u001b[38;5;28mself\u001b[39m.input_layernorm, hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m hidden_states, self_attn_weights, present_key_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m       \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m         \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    599\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m      \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    600\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m   \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m           \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m        \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    605\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    607\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/venv/lib/python3.11/site-packages/unsloth/models/llama.py:516\u001b[39m, in \u001b[36mLlamaAttention_fast_forward\u001b[39m\u001b[34m(self, hidden_states, causal_mask, attention_mask, position_ids, past_key_value, output_attentions, use_cache, padding_mask, position_embeddings, *args, **kwargs)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    512\u001b[39m     \u001b[38;5;66;03m# Grouped query attention\u001b[39;00m\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m SDPA_HAS_GQA:\n\u001b[32m    514\u001b[39m         \u001b[38;5;66;03m# Needs (batch_size, n_heads, seq_len, head_dim)\u001b[39;00m\n\u001b[32m    515\u001b[39m         \u001b[38;5;66;03m# is_casual and attention_mask must not be both set!\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m         A = \u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_gqa\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_groups\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m         \u001b[38;5;66;03m# Go back to (batch_size, seq_len, n_heads, head_dim)\u001b[39;00m\n\u001b[32m    518\u001b[39m         A = A.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\u001b[38;5;66;03m#.contiguous()\u001b[39;00m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 36.00 GiB. GPU 0 has a total capacity of 79.18 GiB of which 3.72 GiB is free. Process 2072594 has 15.76 GiB memory in use. Including non-PyTorch memory, this process has 59.64 GiB memory in use. Of the allocated memory 58.73 GiB is allocated by PyTorch, and 190.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "trainer_stats = unsloth_train(trainer)#, resume_from_checkpoint = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc56d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log_history(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a422c8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = system_messages[\"malware\"]\n",
    "user_input = format_validation_example_for_inference(dataset[\"eval\"][\"text\"][5])\n",
    "inference(model,\n",
    "          system_message, \n",
    "          user_input, \n",
    "          max_new_tokens=None,\n",
    "          temperature=0.7,\n",
    "          top_p=0.6,\n",
    "          repetition_penalty=1.1,\n",
    "          no_repeat_ngram_size=3,\n",
    "          do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b65137",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"eval\"][\"text\"][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcc79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"info@olymp.is\" in dataset[\"eval\"][\"text\"][134]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94092b72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
