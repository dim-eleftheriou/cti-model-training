{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1660dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install -q numpy\n",
    "!uv pip install -q \"torch>=2.8.0\" \"triton>=3.4.0\"\n",
    "!uv pip install -q \"unsloth_zoo[base] @ git+https://github.com/unslothai/unsloth-zoo\"\n",
    "!uv pip install -q 'unsloth[base] @ git+https://github.com/unslothai/unsloth'\n",
    "!uv pip install -q torchvision bitsandbytes\n",
    "!uv pip install -q 'git+https://github.com/huggingface/transformers'\n",
    "!uv pip install -q 'git+https://github.com/triton-lang/triton.git@05b2c186c1b6c9a08375389d5efe9cb4c401c075#subdirectory=python/triton_kernels'\n",
    "!uv pip install -q setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f3190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def load_json(path:str, filename:str):\n",
    "    with open(os.path.join(path, filename), mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def format_example(example:dict, system_message):\n",
    "        formatted_example = [\n",
    "            {\"role\": \"assistant\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": example[\"input\"]},\n",
    "            {\"role\": \"assistant\", \"content\": json.dumps(example[\"output\"])}\n",
    "        ]\n",
    "        return formatted_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8ad6f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_messages = {\n",
    "    \"malware\":\"\"\"You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
    "                    Your task is to identify all malwares referenced or implied in a CTI report. \n",
    "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
    "                    that describe malwares.\n",
    "                    To describe a malware you should provide the fields id, type, name and is_family.\n",
    "                    Instead of using UUID in the id field, use the rule type--name for generating ids.\n",
    "                    If no malwares are identified return a json with an empty list \"objects\".\n",
    "                    Identify all malwares in the folowing CTI report: \"\"\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c365b1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deleftheriou/cti-model-training/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Skipping import of cpp extensions due to incompatible torch version 2.9.0+cu128 for torchao version 0.14.0         Please see GitHub issue #2919 for more info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Unsloth: `hf_xet==1.1.10` and `ipykernel>6.30.1` breaks progress bars. Disabling for now in XET.\n",
      "#### Unsloth: To re-enable progress bars, please downgrade to `ipykernel==6.30.1` or wait for a fix to\n",
      "https://github.com/huggingface/xet-core/issues/526\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unsloth/gpt-oss-20b-unsloth-bnb-4bit/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unsloth/gpt-oss-20b-unsloth-bnb-4bit/093fba6992ef5a7152481afec0bdfca1ac486998/config.json \"HTTP/1.1 200 OK\"\n",
      "Unrecognized keys in `rope_parameters` for 'rope_type'='yarn': {'truncate'}\n",
      "Unrecognized keys in `rope_parameters` for 'rope_type'='yarn': {'truncate'}\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unsloth/gpt-oss-20b-unsloth-bnb-4bit/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/models/unsloth/gpt-oss-20b-unsloth-bnb-4bit \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/models/unsloth/gpt-oss-20b-unsloth-bnb-4bit/revision/main \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/models/unsloth/gpt-oss-20b-unsloth-bnb-4bit/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unsloth/gpt-oss-20b-unsloth-bnb-4bit/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unsloth/gpt-oss-20b-unsloth-bnb-4bit/093fba6992ef5a7152481afec0bdfca1ac486998/config.json \"HTTP/1.1 200 OK\"\n",
      "Unrecognized keys in `rope_parameters` for 'rope_type'='yarn': {'truncate'}\n",
      "Unrecognized keys in `rope_parameters` for 'rope_type'='yarn': {'truncate'}\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unsloth/gpt-oss-20b-unsloth-bnb-4bit/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.10.8: Fast Gpt_Oss patching. Transformers: 5.0.0.dev0.\n",
      "   \\\\   /|    NVIDIA H100 PCIe. Num GPUs = 1. Max memory: 79.179 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.9.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.5.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/models/unslothai/other/revision/main \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/other/resolve/43d9e0f2f19a5d7836895f648dc0e762816acf77/.gitattributes \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unslothai/other/43d9e0f2f19a5d7836895f648dc0e762816acf77/.gitattributes \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/unslothai/other/43d9e0f2f19a5d7836895f648dc0e762816acf77/.gitattributes \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/other/resolve/43d9e0f2f19a5d7836895f648dc0e762816acf77/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unslothai/other/43d9e0f2f19a5d7836895f648dc0e762816acf77/README.md \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/unslothai/other/43d9e0f2f19a5d7836895f648dc0e762816acf77/README.md \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/other/resolve/43d9e0f2f19a5d7836895f648dc0e762816acf77/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unslothai/other/43d9e0f2f19a5d7836895f648dc0e762816acf77/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/unslothai/other/43d9e0f2f19a5d7836895f648dc0e762816acf77/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/other/resolve/43d9e0f2f19a5d7836895f648dc0e762816acf77/model.safetensors \"HTTP/1.1 302 Found\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/models/unslothai/other/xet-read-token/43d9e0f2f19a5d7836895f648dc0e762816acf77 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/models/unslothai/repeat/revision/main \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/repeat/resolve/7c48478c02f84ed89f149b0815cc0216ee831fb0/.gitattributes \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unslothai/repeat/7c48478c02f84ed89f149b0815cc0216ee831fb0/.gitattributes \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/unslothai/repeat/7c48478c02f84ed89f149b0815cc0216ee831fb0/.gitattributes \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/repeat/resolve/7c48478c02f84ed89f149b0815cc0216ee831fb0/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unslothai/repeat/7c48478c02f84ed89f149b0815cc0216ee831fb0/README.md \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/unslothai/repeat/7c48478c02f84ed89f149b0815cc0216ee831fb0/README.md \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/repeat/resolve/7c48478c02f84ed89f149b0815cc0216ee831fb0/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unslothai/repeat/7c48478c02f84ed89f149b0815cc0216ee831fb0/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/unslothai/repeat/7c48478c02f84ed89f149b0815cc0216ee831fb0/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/repeat/resolve/7c48478c02f84ed89f149b0815cc0216ee831fb0/model.safetensors \"HTTP/1.1 302 Found\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/models/unslothai/repeat/xet-read-token/7c48478c02f84ed89f149b0815cc0216ee831fb0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/models/unslothai/vram-80/revision/main \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/vram-80/resolve/830433cec98f0aa155f72baba38dc9fe6831d3f3/.gitattributes \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unslothai/vram-80/830433cec98f0aa155f72baba38dc9fe6831d3f3/.gitattributes \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/unslothai/vram-80/830433cec98f0aa155f72baba38dc9fe6831d3f3/.gitattributes \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/vram-80/resolve/830433cec98f0aa155f72baba38dc9fe6831d3f3/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unslothai/vram-80/830433cec98f0aa155f72baba38dc9fe6831d3f3/README.md \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/unslothai/vram-80/830433cec98f0aa155f72baba38dc9fe6831d3f3/README.md \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/vram-80/resolve/830433cec98f0aa155f72baba38dc9fe6831d3f3/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unslothai/vram-80/830433cec98f0aa155f72baba38dc9fe6831d3f3/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/unslothai/vram-80/830433cec98f0aa155f72baba38dc9fe6831d3f3/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/vram-80/resolve/830433cec98f0aa155f72baba38dc9fe6831d3f3/model.safetensors \"HTTP/1.1 302 Found\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/models/unslothai/vram-80/xet-read-token/830433cec98f0aa155f72baba38dc9fe6831d3f3 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/models/unslothai/1/revision/main \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/1/resolve/7ec782b7604cd9ea0781c23a4270f031650f5617/.gitattributes \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unslothai/1/7ec782b7604cd9ea0781c23a4270f031650f5617/.gitattributes \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/unslothai/1/7ec782b7604cd9ea0781c23a4270f031650f5617/.gitattributes \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/1/resolve/7ec782b7604cd9ea0781c23a4270f031650f5617/README.md \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unslothai/1/7ec782b7604cd9ea0781c23a4270f031650f5617/README.md \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/unslothai/1/7ec782b7604cd9ea0781c23a4270f031650f5617/README.md \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/1/resolve/7ec782b7604cd9ea0781c23a4270f031650f5617/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unslothai/1/7ec782b7604cd9ea0781c23a4270f031650f5617/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/resolve-cache/models/unslothai/1/7ec782b7604cd9ea0781c23a4270f031650f5617/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unslothai/1/resolve/7ec782b7604cd9ea0781c23a4270f031650f5617/model.safetensors \"HTTP/1.1 302 Found\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/models/unslothai/1/xet-read-token/7ec782b7604cd9ea0781c23a4270f031650f5617 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unsloth/gpt-oss-20b-unsloth-bnb-4bit/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unsloth/gpt-oss-20b-unsloth-bnb-4bit/093fba6992ef5a7152481afec0bdfca1ac486998/config.json \"HTTP/1.1 200 OK\"\n",
      "Unrecognized keys in `rope_parameters` for 'rope_type'='yarn': {'truncate'}\n",
      "Unrecognized keys in `rope_parameters` for 'rope_type'='yarn': {'truncate'}\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unsloth/gpt-oss-20b-unsloth-bnb-4bit/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unsloth/gpt-oss-20b-unsloth-bnb-4bit/093fba6992ef5a7152481afec0bdfca1ac486998/config.json \"HTTP/1.1 200 OK\"\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:12<00:00,  3.03s/it]\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unsloth/gpt-oss-20b-unsloth-bnb-4bit/resolve/main/generation_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unsloth/gpt-oss-20b-unsloth-bnb-4bit/093fba6992ef5a7152481afec0bdfca1ac486998/generation_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unsloth/gpt-oss-20b-unsloth-bnb-4bit/resolve/main/custom_generate/generate.py \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/unsloth/gpt-oss-20b-unsloth-bnb-4bit/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx: HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/unsloth/gpt-oss-20b-unsloth-bnb-4bit/093fba6992ef5a7152481afec0bdfca1ac486998/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx: HTTP Request: GET https://huggingface.co/api/models/unsloth/gpt-oss-20b-unsloth-bnb-4bit/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "    config = yaml.load(f, Loader=yaml.SafeLoader)\n",
    "\n",
    "\n",
    "max_seq_length = 1024\n",
    "dtype = None\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/gpt-oss-20b\",\n",
    "    fast_inference = False,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit = True,\n",
    "    max_seq_length = max_seq_length,\n",
    "    gpu_memory_utilization = 0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4450b479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's context window: 1024\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model's context window: {model.max_seq_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba51a8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "It follows an example of a formatted instruction using chat template. If instruction_part and\n",
      "response_part have been defined in config.yaml, please verify their correctness.\n",
      "\n",
      "CHAT TEMPLATE\n",
      "\n",
      "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\n",
      "Knowledge cutoff: 2024-06\n",
      "Current date: 2025-10-23\n",
      "\n",
      "Reasoning: medium\n",
      "\n",
      "# Valid channels: analysis, commentary, final. Channel must be included for every message.\n",
      "Calls to these tools must go to the commentary channel: 'functions'.<|end|><|start|>assistant<|message|>SYSTEM MESSAGE PLACEHOLDER<|end|><|start|>user<|message|>USER INPUT MESSAGE PLACEHOLDER<|end|><|start|>assistant<|message|>MODEL RESPONSE MESSAGE PLACEHOLDER<|return|>\n"
     ]
    }
   ],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "# Example of chat template\n",
    "convo = [\n",
    "    {\"role\": \"assistant\", \"content\": \"SYSTEM MESSAGE PLACEHOLDER\"},\n",
    "    {\"role\": \"user\", \"content\": \"USER INPUT MESSAGE PLACEHOLDER\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"MODEL RESPONSE MESSAGE PLACEHOLDER\"}\n",
    "]\n",
    "\n",
    "res = tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False)\n",
    "print(f\"\"\"\\nIt follows an example of a formatted instruction using chat template. If instruction_part and\n",
    "response_part have been defined in config.yaml, please verify their correctness.\\n\\nCHAT TEMPLATE\\n\\n{res}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb93211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer\n",
    "import torch\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "\n",
    "def format_input_prompt(system_message, user_input):\n",
    "    formatted_input = [\n",
    "        {\"role\": \"assistant\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_input}\n",
    "    ]\n",
    "    return formatted_input\n",
    "\n",
    "def format_validation_example_for_inference(example):\n",
    "    return example.split(\"<|start|>user<|message|>\")[1].split(\"<|start|>assistant<|channel|>final<|message|>\")[0].split(\"<|end|>\")[0]\n",
    "                         \n",
    "def inference(model, system_message, user_input, max_new_tokens=None, **kwargs):\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        format_input_prompt(system_message, user_input),\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=True,\n",
    "\t    return_dict=True,\n",
    "        return_tensors = \"pt\").to(model.device)\n",
    "\n",
    "    # Cast attention_mask to bool (recommended)\n",
    "    inputs[\"attention_mask\"] = inputs[\"attention_mask\"].to(torch.bool)\n",
    "\n",
    "    if not max_new_tokens:\n",
    "        max_new_tokens = model.config.max_position_embeddings - inputs[\"input_ids\"].shape[-1]\n",
    "    model.generate(**inputs, streamer = text_streamer, max_new_tokens=max_new_tokens, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e95c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"/mnt/data/openCTI/splitted-io-pairs/train\"\n",
    "validation_path = \"/mnt/data/openCTI/splitted-io-pairs/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c500ddd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_train_list = []\n",
    "formatted_eval_list = []\n",
    "include_cti_type = [\"malware\"]\n",
    "\n",
    "for file in os.listdir(train_path):\n",
    "    cti_type = file.split(\"--\")[0]\n",
    "    if cti_type not in include_cti_type:\n",
    "        continue\n",
    "    example = load_json(train_path, file)\n",
    "    formatted_example = format_example(example, system_messages[cti_type])\n",
    "    formatted_train_list.append(formatted_example)\n",
    "\n",
    "for file in os.listdir(validation_path):\n",
    "    cti_type = file.split(\"--\")[0]\n",
    "    if cti_type not in include_cti_type:\n",
    "        continue\n",
    "    example = load_json(validation_path, file)\n",
    "    formatted_example = format_example(example, system_messages[cti_type])\n",
    "    formatted_eval_list.append(formatted_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74df148d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=30): 100%|██████████| 1858/1858 [00:17<00:00, 107.86 examples/s]\n",
      "Filter (num_proc=30): 100%|██████████| 301/301 [00:04<00:00, 69.26 examples/s] \n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from multiprocessing import cpu_count\n",
    "num_proc = cpu_count()\n",
    "\n",
    "filter_dataset = True\n",
    "filter_threshold = 40960\n",
    "\n",
    "# Add template of the model in examples\n",
    "templated_train_list = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in formatted_train_list]\n",
    "templated_eval_list = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in formatted_eval_list]\n",
    "# Create hf seperated datasets\n",
    "hf_train = datasets.Dataset.from_list([dict(text=ex) for ex in templated_train_list])\n",
    "hf_eval = datasets.Dataset.from_list([dict(text=ex) for ex in templated_eval_list])\n",
    "# Create a hf dataset dict\n",
    "dataset = datasets.DatasetDict({\"train\":hf_train, \"eval\":hf_eval})\n",
    "# Filter dataset\n",
    "if filter_dataset:\n",
    "    if not filter_threshold:\n",
    "        filter_threshold = tokenizer.model_max_length\n",
    "    dataset = dataset.filter(lambda x: len(tokenizer.encode(x[\"text\"])) <= filter_threshold,\n",
    "                             num_proc=num_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfb7fed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\n",
      "Knowledge cutoff: 2024-06\n",
      "Current date: 2025-10-23\n",
      "\n",
      "Reasoning: medium\n",
      "\n",
      "# Valid channels: analysis, commentary, final. Channel must be included for every message.\n",
      "Calls to these tools must go to the commentary channel: 'functions'.<|end|><|start|>assistant<|message|>You are an AI Security Analyst in Cyberthreat Intelligence (CTI). \n",
      "                    Your task is to identify all malwares referenced or implied in a CTI report. \n",
      "                    You MUST return a json with a field \"objects\" being a list of json objects \n",
      "                    that describe malwares.\n",
      "                    To describe a malware you should provide the fields id, type, name and is_family.\n",
      "                    Instead of using UUID in the id field, use the rule type--name for generating ids.\n",
      "                    If no malwares are identified return a json with an empty list \"objects\".\n",
      "                    Identify all malwares in the folowing CTI report: <|end|><|start|>user<|message|>External reference URL: https://www.fortinet.com/blog/threat-research/new-midgedropper-variant\n",
      "\n",
      "CTI REPORT\n",
      "\n",
      "# New MidgeDropper Variant\n",
      "\n",
      "Affected Platforms: Windows\n",
      "\n",
      "Impacted Users: Windows users\n",
      "\n",
      "Impact: Potential to deploy additional malware for additional purposes\n",
      "\n",
      "Severity Level: Medium\n",
      "\n",
      "One of the most exciting aspects of malware analysis is coming across a family that is new or rare to the reversing community. Determining the function of the malware, who created it, and the reasons behind it become a mystery to solve. The previously unseen dropper variant we recently found, named MidgeDropper, has a complex infection chain that includes code obfuscation and sideloading, making it an interesting use case. Although we couldn’t obtain the final payload, this blog will still explore what makes this dropper tick.\n",
      "\n",
      "## Initial Infection Vector\n",
      "\n",
      "The initial infection vector was not available to FortiGuard Labs at the time of our investigation. However, we strongly suspect it to be a phishing e-mail because we have access to an RAR archive—!PENTING\\_LIST OF OFFICERS.rar—that would have been the likely attachment to an e-mail.\n",
      "\n",
      "## !PENTING\\_LIST OF OFFICERS.rar\n",
      "\n",
      "Two files are in the !PENTING\\_LIST OF OFFICERS.rar archive: “Notice to Work-From-Home groups.pdf” and “062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” (Figure 1).\n",
      "\n",
      "\n",
      "\n",
      "## Notice to Work-From-Home groups.pdf\n",
      "\n",
      "The “Notice to Work-From-Home groups.pdf” file is exactly what it appears to be: a PDF file. It contains an image of an error message that falsely indicates that the PDF document failed to load. It is designed to act as a decoy and shift the recipient’s attention to clicking on and executing the “062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” file. Since file extensions are hidden by default in Windows, it is unlikely that anyone reviewing the contents would see the “.exe” and would instead assume they were opening another PDF file.\n",
      "\n",
      "\n",
      "\n",
      "## 062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe\n",
      "\n",
      "At 6.7MB, the ”062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” file is large by malware delivery standards. This executable primarily functions as a dropper for the following stages of infection.\n",
      "\n",
      "The executable drops the files “Microsoft Office.doc,” “IC.exe,” “power.exe,” and “power.xml”. It also reaches out to “hXXp://185[.]225[.]68[.]37/jay/nl/seAgnt.exe” to pull down the file “seAgnt.exe.”\n",
      "\n",
      "\n",
      "\n",
      "## Microsoft Office.doc\n",
      "\n",
      "This file is dropped and opened from “C:\\Users\\&lt;user&gt;\\AppData\\Local\\Temp\\Microsoft\\Office.” It is also meant to be a decoy. It is populated in some versions of the dropper, but it was empty and benign in the version analyzed by FortiGuard Labs.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## IC.exe\n",
      "\n",
      "“IC.exe” is dropped by “062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” and deposited into “C:\\ProgramData\\Emisoft\\Microsoft\\Stream\\IC.exe.” It is responsible for obtaining the next stage of the infection.\n",
      "\n",
      "\n",
      "\n",
      "“IC.exe” reaches out to a URL at “185[.]225[.]68[.]37” to download an additional file, “VCRUNTIME140\\_1.dll.”\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "As can probably be guessed by the filename, “VCRUNTIME140\\_1.dll” is meant to appear as a file related to the Microsoft Visual C++ Redistributable Package.\n",
      "\n",
      "## power.exe and power.xml\n",
      "\n",
      "“power.exe” is dropped along with “power.xml” by ”062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe”.  “power.exe” only has one job: decoding and processing “power.xml.”\n",
      "\n",
      "\n",
      "\n",
      "Figure 9 shows that “power.xml” in its native format is obfuscated and not readily readable.  This can be easily rectified by removing the garbage characters used for obfuscation.\n",
      "\n",
      "\n",
      "\n",
      "With obfuscation removed, an XML document remains. Much of the information is irrelevant except for the final section under the “Actions” tag. The primary purpose of this pair of files is to launch “seAgnt.exe.”\n",
      "\n",
      "## seAgnt.exe\n",
      "\n",
      "“seAgnt.exe” is a renamed copy of “GameBarFTServer.exe,” which is an application published by Microsoft, “Xbox Game Bar Full Trust COM Server.”  It is a background process for the Xbox Game Bar that runs on Windows.\n",
      "\n",
      "\n",
      "\n",
      "Although itself benign, “seAgnt.exe” does depend on “VCRUNTIME140\\_1.dll”.  This dependency allows the malicious code inside of the DLL to execute.\n",
      "\n",
      "\n",
      "\n",
      "## VCRUNTIME140\\_1.dll\n",
      "\n",
      "“VCRUNTIME140\\_1.dll” is a legitimate DLL that is part of the Microsoft Visual C++ runtime package. Unfortunately, the particular version used here is malicious.\n",
      "\n",
      "Due to “VCRUNTIME140\\_1.dll” being a Dynamic Link Library, it doesn’t exist as a separate executable. It has to have assistance via another application to load its code into memory and execute it. “seAgnt.exe” is that application. This technique is called sideloading (https://attack.mitre.org/techniques/T1574/002/) because a dependency of a legitimate application is highjacked to allow the malicious code to load.\n",
      "\n",
      "\n",
      "\n",
      "The file is heavily obfuscated and designed to make analysis much more difficult. For example, the figure below shows the massive number of function jumps that attempt to hide the purpose of the code.\n",
      "\n",
      "\n",
      "\n",
      "The rest of the code makes it equally difficult to follow along in a disassembler.\n",
      "\n",
      "The primary purpose of the code appears to be reaching out to “hXXp://185[.]225[.]68[.]37/jay/nl/35g3498734gkb.dat” to pull down the file “35g3498734gkb.dat”.\n",
      "\n",
      "\n",
      "\n",
      "## 35g3498734gkb.dat\n",
      "\n",
      "Oddly, “35g3498734gkb.dat” is identical to “VCRUNTIME140\\_1.dll” in terms of the file hash, so it’s unclear why the threat actor opted to pull it down again from the C2 node.\n",
      "\n",
      "\n",
      "\n",
      "Unfortunately, further links on the infection chain were taken down when our analysis began, preventing further analysis of any potential final payloads.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Despite the final payload being unavailable before FortiGuard Labs could analyze it, this dropper made an interesting case study and provided a subject to watch out for.\n",
      "\n",
      "## Fortinet Protections\n",
      "\n",
      "Fortinet customers are already protected from this malware through FortiGuard’s Web Filtering, AntiVirus, FortiMail, FortiClient, and FortiEDR services, as follows:\n",
      "\n",
      "The following (AV) signature detects the malware samples mentioned in this blog\n",
      "\n",
      "- MalwThreat!caa0FT\n",
      "- W32/Agent.9CDF!tr\n",
      "\n",
      "The WebFiltering client blocks all network-based URIs.\n",
      "\n",
      "Fortinet has multiple solutions designed to help train users to understand and detect phishing threats:\n",
      "\n",
      "The FortiPhish Phishing Simulation Service uses real-world simulations to help organizations test user awareness and vigilance to phishing threats and to train and reinforce proper practices when users encounter targeted phishing attacks.\n",
      "\n",
      "We also suggest that organizations have their end users undergo our FREE NSE training: NSE 1 – Information Security Awareness. It includes a module on Internet threats designed to help end users learn how to identify and protect themselves from various types of phishing attacks.\n",
      "\n",
      "If you think this or any other cybersecurity threat has impacted your organization, contact our Global FortiGuard Incident Response Team.\n",
      "\n",
      "## IOCs\n",
      "\n",
      "### File-based IOCs:\n",
      "\n",
      "| Filename                                                                      | SHA256                                                           |\n",
      "|-------------------------------------------------------------------------------|------------------------------------------------------------------|\n",
      "| !PENTING_LIST OF OFFICERS.rar                                                 | 2dcf00b0f6c41c2c60561ca92893a0a9bf060e1d46af426de022d0c5d23d8704 |\n",
      "| Notice to Work-From-Home groups.pdf                                           | 30417ca261eefe40f7c44ff956f9940b766ae9a0c574cd1c06a4b545e46f692e |\n",
      "| 062023_PENTING_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe | c22cc7111191e5a1a2010f4bc3127058bff41ecba8d753378feabee37d5b43bb |\n",
      "| Microsoft Office.doc                                                          | 59334a6e2c5faabe3a1baf5347ba01f2419d731fcbb7ab1b021185c059c8fa6f |\n",
      "| IC.exe                                                                        | fc40e782731b8d3b9ec5e5cf8a9d8b8126dc05028ca58ec52db155b3dadc5fc6 |\n",
      "| power.exe                                                                     | f26f5a52bddda5eb3245161b784b58635ffa2381818816e50b8bae9680ff88eb |\n",
      "| power.xml                                                                     | f43cca8d2e996ee78edf8d9e64e05f35e94a730fbe51e9feecc5e364280d8534 |\n",
      "| seAgnt.exe                                                                    | b3e0388f215ac127b647cd7d3f186f2f666dc0535d66797b6e1adb74f828254e |\n",
      "| VCRUNTIME140_1.dll / 35g3498734gkb.dat                                        | 527afa0c415af005594acaac1093a1ea79e3639fa5563602497eabbae7438130 |\n",
      "\n",
      "### Network-based IOCs:\n",
      "\n",
      "| IOC                                                  | IOC type                |\n",
      "|------------------------------------------------------|-------------------------|\n",
      "| 185[.]225[.]69[.]226                                 | C2 Node                 |\n",
      "| hXXp://185[.]225[.]68[.]37/jay/nl/VCRUNTIME140_1.dll | Stage download location |\n",
      "| hXXp://185[.]225[.]68[.]37/jay/nl/seAgnt.exe         | Stage download location |\n",
      "| hXXp://185[.]225[.]68[.]37/jay/nl/35g3498734gkb.dat  | Stage download location |\n",
      "\n",
      "### Related Posts\n",
      "\n",
      "\n",
      "\n",
      "FortiGuard Labs Threat Research\n",
      "\n",
      "##### Ransomware Roundup - Rhysida\n",
      "\n",
      "\n",
      "\n",
      "FortiGuard Labs Threat Research\n",
      "\n",
      "##### Ransomware Roundup – Trash Panda and A New Minor Variant of NoCry\n",
      "\n",
      "\n",
      "\n",
      "FortiGuard Labs Threat Research\n",
      "\n",
      "##### Ransomware Roundup - DoDo and Proton\n",
      "\n",
      "\n",
      "\n",
      "#### News &amp; Articles\n",
      "\n",
      "- News Releases\n",
      "- News Articles\n",
      "\n",
      "#### Security Research\n",
      "\n",
      "- Threat Research\n",
      "- FortiGuard Labs\n",
      "- Threat Map\n",
      "- Ransomware Prevention\n",
      "\n",
      "#### Connect With Us\n",
      "\n",
      "- Fortinet Community\n",
      "- Partner Portal\n",
      "- Investor Relations\n",
      "- Product Certifications\n",
      "\n",
      "#### Company\n",
      "\n",
      "- About Us\n",
      "- Exec Mgmt\n",
      "- Careers\n",
      "- Training\n",
      "- Events\n",
      "- Industry Awards\n",
      "- Social Responsibility\n",
      "- CyberGlossary\n",
      "- Sitemap\n",
      "- Blog Sitemap\n",
      "\n",
      "#### Contact Us\n",
      "\n",
      "- (866) 868-3678\n",
      "\n",
      "Copyright © 2025 Fortinet, Inc. All Rights Reserved\n",
      "\n",
      "Also of Interest:\n",
      "\n",
      "- Progress against vulnerabilities\n",
      "- Network Security Vulnerabilities\n",
      "- FortiGuard Labs Threat Research\n",
      "- Pay Ransomware Settlements?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "########################################################################################################################################################################################################\n",
      "\n",
      "\n",
      "External reference URL: https://otx.alienvault.com/pulse/650815eae6309eba75a1d6a2\n",
      "\n",
      "CTI REPORT\n",
      "\n",
      "# Title #\n",
      "New MidgeDropper Variant\n",
      "\n",
      "# Metadata #\n",
      "Created 2 years ago by AlienVault Public TLP:  White\n",
      "\n",
      "# Contents #\n",
      "Tags: MidgeDropper, Obfuscation, phishing, RAR archive\n",
      "\n",
      "Group:  2MISP\n",
      "\n",
      "Malware Family: MidgeDropper\n",
      "\n",
      "Att&ck IDs: T1566 - Phishing ,  T1001 - Data Obfuscation ,  T1027 - Obfuscated Files or Information ,  T1083 - File and Directory Discovery ,  T1071 - Application Layer Protocol ,  T1073 - DLL Side-Loading\n",
      "\n",
      "# Indicators of Compromise #\n",
      "           type                                                        indicator Role title                    Added Active related Pulses\n",
      "FileHash-SHA256 2dcf00b0f6c41c2c60561ca92893a0a9bf060e1d46af426de022d0c5d23d8704            Sep 18, 2023, 9:18:35 AM                     6\n",
      "FileHash-SHA256 30417ca261eefe40f7c44ff956f9940b766ae9a0c574cd1c06a4b545e46f692e            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 527afa0c415af005594acaac1093a1ea79e3639fa5563602497eabbae7438130            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 59334a6e2c5faabe3a1baf5347ba01f2419d731fcbb7ab1b021185c059c8fa6f            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 b3e0388f215ac127b647cd7d3f186f2f666dc0535d66797b6e1adb74f828254e            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 c22cc7111191e5a1a2010f4bc3127058bff41ecba8d753378feabee37d5b43bb            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 f26f5a52bddda5eb3245161b784b58635ffa2381818816e50b8bae9680ff88eb            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 f43cca8d2e996ee78edf8d9e64e05f35e94a730fbe51e9feecc5e364280d8534            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 fc40e782731b8d3b9ec5e5cf8a9d8b8126dc05028ca58ec52db155b3dadc5fc6            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                                     http://185.225.68.37/jay/nl/            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                    http://185.225.68.37/jay/nl/35g3498734gkb.dat            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL           http://185.225.68.37/jay/nl/35g3498734gkb.xn--dat-9o0a            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                   http://185.225.68.37/jay/nl/VCRUNTIME140_1.dll            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                           http://185.225.68.37/jay/nl/seAgnt.exe            Sep 18, 2023, 9:18:35 AM                     5\n",
      "\n",
      "<|end|><|start|>assistant<|message|>{\"objects\": [{\"id\": \"malware--MidgeDropper\", \"type\": \"malware\", \"name\": \"MidgeDropper\", \"is_family\": false}]}<|return|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][\"text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4400e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External reference URL: https://www.fortinet.com/blog/threat-research/new-midgedropper-variant\n",
      "\n",
      "CTI REPORT\n",
      "\n",
      "# New MidgeDropper Variant\n",
      "\n",
      "Affected Platforms: Windows\n",
      "\n",
      "Impacted Users: Windows users\n",
      "\n",
      "Impact: Potential to deploy additional malware for additional purposes\n",
      "\n",
      "Severity Level: Medium\n",
      "\n",
      "One of the most exciting aspects of malware analysis is coming across a family that is new or rare to the reversing community. Determining the function of the malware, who created it, and the reasons behind it become a mystery to solve. The previously unseen dropper variant we recently found, named MidgeDropper, has a complex infection chain that includes code obfuscation and sideloading, making it an interesting use case. Although we couldn’t obtain the final payload, this blog will still explore what makes this dropper tick.\n",
      "\n",
      "## Initial Infection Vector\n",
      "\n",
      "The initial infection vector was not available to FortiGuard Labs at the time of our investigation. However, we strongly suspect it to be a phishing e-mail because we have access to an RAR archive—!PENTING\\_LIST OF OFFICERS.rar—that would have been the likely attachment to an e-mail.\n",
      "\n",
      "## !PENTING\\_LIST OF OFFICERS.rar\n",
      "\n",
      "Two files are in the !PENTING\\_LIST OF OFFICERS.rar archive: “Notice to Work-From-Home groups.pdf” and “062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” (Figure 1).\n",
      "\n",
      "\n",
      "\n",
      "## Notice to Work-From-Home groups.pdf\n",
      "\n",
      "The “Notice to Work-From-Home groups.pdf” file is exactly what it appears to be: a PDF file. It contains an image of an error message that falsely indicates that the PDF document failed to load. It is designed to act as a decoy and shift the recipient’s attention to clicking on and executing the “062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” file. Since file extensions are hidden by default in Windows, it is unlikely that anyone reviewing the contents would see the “.exe” and would instead assume they were opening another PDF file.\n",
      "\n",
      "\n",
      "\n",
      "## 062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe\n",
      "\n",
      "At 6.7MB, the ”062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” file is large by malware delivery standards. This executable primarily functions as a dropper for the following stages of infection.\n",
      "\n",
      "The executable drops the files “Microsoft Office.doc,” “IC.exe,” “power.exe,” and “power.xml”. It also reaches out to “hXXp://185[.]225[.]68[.]37/jay/nl/seAgnt.exe” to pull down the file “seAgnt.exe.”\n",
      "\n",
      "\n",
      "\n",
      "## Microsoft Office.doc\n",
      "\n",
      "This file is dropped and opened from “C:\\Users\\&lt;user&gt;\\AppData\\Local\\Temp\\Microsoft\\Office.” It is also meant to be a decoy. It is populated in some versions of the dropper, but it was empty and benign in the version analyzed by FortiGuard Labs.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## IC.exe\n",
      "\n",
      "“IC.exe” is dropped by “062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe” and deposited into “C:\\ProgramData\\Emisoft\\Microsoft\\Stream\\IC.exe.” It is responsible for obtaining the next stage of the infection.\n",
      "\n",
      "\n",
      "\n",
      "“IC.exe” reaches out to a URL at “185[.]225[.]68[.]37” to download an additional file, “VCRUNTIME140\\_1.dll.”\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "As can probably be guessed by the filename, “VCRUNTIME140\\_1.dll” is meant to appear as a file related to the Microsoft Visual C++ Redistributable Package.\n",
      "\n",
      "## power.exe and power.xml\n",
      "\n",
      "“power.exe” is dropped along with “power.xml” by ”062023\\_PENTING\\_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe”.  “power.exe” only has one job: decoding and processing “power.xml.”\n",
      "\n",
      "\n",
      "\n",
      "Figure 9 shows that “power.xml” in its native format is obfuscated and not readily readable.  This can be easily rectified by removing the garbage characters used for obfuscation.\n",
      "\n",
      "\n",
      "\n",
      "With obfuscation removed, an XML document remains. Much of the information is irrelevant except for the final section under the “Actions” tag. The primary purpose of this pair of files is to launch “seAgnt.exe.”\n",
      "\n",
      "## seAgnt.exe\n",
      "\n",
      "“seAgnt.exe” is a renamed copy of “GameBarFTServer.exe,” which is an application published by Microsoft, “Xbox Game Bar Full Trust COM Server.”  It is a background process for the Xbox Game Bar that runs on Windows.\n",
      "\n",
      "\n",
      "\n",
      "Although itself benign, “seAgnt.exe” does depend on “VCRUNTIME140\\_1.dll”.  This dependency allows the malicious code inside of the DLL to execute.\n",
      "\n",
      "\n",
      "\n",
      "## VCRUNTIME140\\_1.dll\n",
      "\n",
      "“VCRUNTIME140\\_1.dll” is a legitimate DLL that is part of the Microsoft Visual C++ runtime package. Unfortunately, the particular version used here is malicious.\n",
      "\n",
      "Due to “VCRUNTIME140\\_1.dll” being a Dynamic Link Library, it doesn’t exist as a separate executable. It has to have assistance via another application to load its code into memory and execute it. “seAgnt.exe” is that application. This technique is called sideloading (https://attack.mitre.org/techniques/T1574/002/) because a dependency of a legitimate application is highjacked to allow the malicious code to load.\n",
      "\n",
      "\n",
      "\n",
      "The file is heavily obfuscated and designed to make analysis much more difficult. For example, the figure below shows the massive number of function jumps that attempt to hide the purpose of the code.\n",
      "\n",
      "\n",
      "\n",
      "The rest of the code makes it equally difficult to follow along in a disassembler.\n",
      "\n",
      "The primary purpose of the code appears to be reaching out to “hXXp://185[.]225[.]68[.]37/jay/nl/35g3498734gkb.dat” to pull down the file “35g3498734gkb.dat”.\n",
      "\n",
      "\n",
      "\n",
      "## 35g3498734gkb.dat\n",
      "\n",
      "Oddly, “35g3498734gkb.dat” is identical to “VCRUNTIME140\\_1.dll” in terms of the file hash, so it’s unclear why the threat actor opted to pull it down again from the C2 node.\n",
      "\n",
      "\n",
      "\n",
      "Unfortunately, further links on the infection chain were taken down when our analysis began, preventing further analysis of any potential final payloads.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "Despite the final payload being unavailable before FortiGuard Labs could analyze it, this dropper made an interesting case study and provided a subject to watch out for.\n",
      "\n",
      "## Fortinet Protections\n",
      "\n",
      "Fortinet customers are already protected from this malware through FortiGuard’s Web Filtering, AntiVirus, FortiMail, FortiClient, and FortiEDR services, as follows:\n",
      "\n",
      "The following (AV) signature detects the malware samples mentioned in this blog\n",
      "\n",
      "- MalwThreat!caa0FT\n",
      "- W32/Agent.9CDF!tr\n",
      "\n",
      "The WebFiltering client blocks all network-based URIs.\n",
      "\n",
      "Fortinet has multiple solutions designed to help train users to understand and detect phishing threats:\n",
      "\n",
      "The FortiPhish Phishing Simulation Service uses real-world simulations to help organizations test user awareness and vigilance to phishing threats and to train and reinforce proper practices when users encounter targeted phishing attacks.\n",
      "\n",
      "We also suggest that organizations have their end users undergo our FREE NSE training: NSE 1 – Information Security Awareness. It includes a module on Internet threats designed to help end users learn how to identify and protect themselves from various types of phishing attacks.\n",
      "\n",
      "If you think this or any other cybersecurity threat has impacted your organization, contact our Global FortiGuard Incident Response Team.\n",
      "\n",
      "## IOCs\n",
      "\n",
      "### File-based IOCs:\n",
      "\n",
      "| Filename                                                                      | SHA256                                                           |\n",
      "|-------------------------------------------------------------------------------|------------------------------------------------------------------|\n",
      "| !PENTING_LIST OF OFFICERS.rar                                                 | 2dcf00b0f6c41c2c60561ca92893a0a9bf060e1d46af426de022d0c5d23d8704 |\n",
      "| Notice to Work-From-Home groups.pdf                                           | 30417ca261eefe40f7c44ff956f9940b766ae9a0c574cd1c06a4b545e46f692e |\n",
      "| 062023_PENTING_LIST OF SUPERVISORY OFFICERS WHO STILL HAVE NOT REPORT.pdf.exe | c22cc7111191e5a1a2010f4bc3127058bff41ecba8d753378feabee37d5b43bb |\n",
      "| Microsoft Office.doc                                                          | 59334a6e2c5faabe3a1baf5347ba01f2419d731fcbb7ab1b021185c059c8fa6f |\n",
      "| IC.exe                                                                        | fc40e782731b8d3b9ec5e5cf8a9d8b8126dc05028ca58ec52db155b3dadc5fc6 |\n",
      "| power.exe                                                                     | f26f5a52bddda5eb3245161b784b58635ffa2381818816e50b8bae9680ff88eb |\n",
      "| power.xml                                                                     | f43cca8d2e996ee78edf8d9e64e05f35e94a730fbe51e9feecc5e364280d8534 |\n",
      "| seAgnt.exe                                                                    | b3e0388f215ac127b647cd7d3f186f2f666dc0535d66797b6e1adb74f828254e |\n",
      "| VCRUNTIME140_1.dll / 35g3498734gkb.dat                                        | 527afa0c415af005594acaac1093a1ea79e3639fa5563602497eabbae7438130 |\n",
      "\n",
      "### Network-based IOCs:\n",
      "\n",
      "| IOC                                                  | IOC type                |\n",
      "|------------------------------------------------------|-------------------------|\n",
      "| 185[.]225[.]69[.]226                                 | C2 Node                 |\n",
      "| hXXp://185[.]225[.]68[.]37/jay/nl/VCRUNTIME140_1.dll | Stage download location |\n",
      "| hXXp://185[.]225[.]68[.]37/jay/nl/seAgnt.exe         | Stage download location |\n",
      "| hXXp://185[.]225[.]68[.]37/jay/nl/35g3498734gkb.dat  | Stage download location |\n",
      "\n",
      "### Related Posts\n",
      "\n",
      "\n",
      "\n",
      "FortiGuard Labs Threat Research\n",
      "\n",
      "##### Ransomware Roundup - Rhysida\n",
      "\n",
      "\n",
      "\n",
      "FortiGuard Labs Threat Research\n",
      "\n",
      "##### Ransomware Roundup – Trash Panda and A New Minor Variant of NoCry\n",
      "\n",
      "\n",
      "\n",
      "FortiGuard Labs Threat Research\n",
      "\n",
      "##### Ransomware Roundup - DoDo and Proton\n",
      "\n",
      "\n",
      "\n",
      "#### News &amp; Articles\n",
      "\n",
      "- News Releases\n",
      "- News Articles\n",
      "\n",
      "#### Security Research\n",
      "\n",
      "- Threat Research\n",
      "- FortiGuard Labs\n",
      "- Threat Map\n",
      "- Ransomware Prevention\n",
      "\n",
      "#### Connect With Us\n",
      "\n",
      "- Fortinet Community\n",
      "- Partner Portal\n",
      "- Investor Relations\n",
      "- Product Certifications\n",
      "\n",
      "#### Company\n",
      "\n",
      "- About Us\n",
      "- Exec Mgmt\n",
      "- Careers\n",
      "- Training\n",
      "- Events\n",
      "- Industry Awards\n",
      "- Social Responsibility\n",
      "- CyberGlossary\n",
      "- Sitemap\n",
      "- Blog Sitemap\n",
      "\n",
      "#### Contact Us\n",
      "\n",
      "- (866) 868-3678\n",
      "\n",
      "Copyright © 2025 Fortinet, Inc. All Rights Reserved\n",
      "\n",
      "Also of Interest:\n",
      "\n",
      "- Progress against vulnerabilities\n",
      "- Network Security Vulnerabilities\n",
      "- FortiGuard Labs Threat Research\n",
      "- Pay Ransomware Settlements?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "########################################################################################################################################################################################################\n",
      "\n",
      "\n",
      "External reference URL: https://otx.alienvault.com/pulse/650815eae6309eba75a1d6a2\n",
      "\n",
      "CTI REPORT\n",
      "\n",
      "# Title #\n",
      "New MidgeDropper Variant\n",
      "\n",
      "# Metadata #\n",
      "Created 2 years ago by AlienVault Public TLP:  White\n",
      "\n",
      "# Contents #\n",
      "Tags: MidgeDropper, Obfuscation, phishing, RAR archive\n",
      "\n",
      "Group:  2MISP\n",
      "\n",
      "Malware Family: MidgeDropper\n",
      "\n",
      "Att&ck IDs: T1566 - Phishing ,  T1001 - Data Obfuscation ,  T1027 - Obfuscated Files or Information ,  T1083 - File and Directory Discovery ,  T1071 - Application Layer Protocol ,  T1073 - DLL Side-Loading\n",
      "\n",
      "# Indicators of Compromise #\n",
      "           type                                                        indicator Role title                    Added Active related Pulses\n",
      "FileHash-SHA256 2dcf00b0f6c41c2c60561ca92893a0a9bf060e1d46af426de022d0c5d23d8704            Sep 18, 2023, 9:18:35 AM                     6\n",
      "FileHash-SHA256 30417ca261eefe40f7c44ff956f9940b766ae9a0c574cd1c06a4b545e46f692e            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 527afa0c415af005594acaac1093a1ea79e3639fa5563602497eabbae7438130            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 59334a6e2c5faabe3a1baf5347ba01f2419d731fcbb7ab1b021185c059c8fa6f            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 b3e0388f215ac127b647cd7d3f186f2f666dc0535d66797b6e1adb74f828254e            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 c22cc7111191e5a1a2010f4bc3127058bff41ecba8d753378feabee37d5b43bb            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 f26f5a52bddda5eb3245161b784b58635ffa2381818816e50b8bae9680ff88eb            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 f43cca8d2e996ee78edf8d9e64e05f35e94a730fbe51e9feecc5e364280d8534            Sep 18, 2023, 9:18:35 AM                     5\n",
      "FileHash-SHA256 fc40e782731b8d3b9ec5e5cf8a9d8b8126dc05028ca58ec52db155b3dadc5fc6            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                                     http://185.225.68.37/jay/nl/            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                    http://185.225.68.37/jay/nl/35g3498734gkb.dat            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL           http://185.225.68.37/jay/nl/35g3498734gkb.xn--dat-9o0a            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                   http://185.225.68.37/jay/nl/VCRUNTIME140_1.dll            Sep 18, 2023, 9:18:35 AM                     5\n",
      "            URL                           http://185.225.68.37/jay/nl/seAgnt.exe            Sep 18, 2023, 9:18:35 AM                     5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_validation_example_for_inference(dataset[\"train\"][\"text\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dfd4995",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 115.06 GiB. GPU 0 has a total capacity of 79.18 GiB of which 57.85 GiB is free. Including non-PyTorch memory, this process has 21.32 GiB memory in use. Of the allocated memory 17.31 GiB is allocated by PyTorch, with 1.34 GiB allocated in private pools (e.g., CUDA Graphs), and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m system_message = system_messages[\u001b[33m\"\u001b[39m\u001b[33mmalware\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      2\u001b[39m user_input = format_validation_example_for_inference(dataset[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m          \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m          \u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m          \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m          \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m          \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m          \u001b[49m\u001b[43mrepetition_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m          \u001b[49m\u001b[43mno_repeat_ngram_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m          \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36minference\u001b[39m\u001b[34m(model, system_message, user_input, max_new_tokens, **kwargs)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m max_new_tokens:\n\u001b[32m     28\u001b[39m     max_new_tokens = model.config.max_position_embeddings - inputs[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[-\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_streamer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/unsloth/models/vision.py:279\u001b[39m, in \u001b[36munsloth_base_fast_generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;66;03m# DO INFERENCE\u001b[39;00m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(), autocaster:\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[38;5;66;03m# Delete cached Flex Attention masks to reset inference\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.named_modules():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:2661\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2658\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2660\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2661\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2662\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2663\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2664\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2665\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2666\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2667\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2668\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2669\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2671\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/transformers/generation/utils.py:2874\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2871\u001b[39m model_inputs = \u001b[38;5;28mself\u001b[39m.prepare_inputs_for_generation(input_ids, **model_kwargs)\n\u001b[32m   2873\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[32m-> \u001b[39m\u001b[32m2874\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2875\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2876\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/unsloth_compiled_cache/unsloth_compiled_module_gpt_oss.py:755\u001b[39m, in \u001b[36mGptOssForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_router_logits, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    742\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    743\u001b[39m     input_ids: Optional[torch.LongTensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    753\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    754\u001b[39m ) -> MoeCausalLMOutputWithPast:\n\u001b[32m--> \u001b[39m\u001b[32m755\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGptOssForCausalLM_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_router_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/_dynamo/external_utils.py:196\u001b[39m, in \u001b[36mget_nonrecursive_disable_wrapper.<locals>.nonrecursive_disable_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnonrecursive_disable_wrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> _R:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/transformers/utils/generic.py:757\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    756\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    759\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/unsloth_compiled_cache/unsloth_compiled_module_gpt_oss.py:576\u001b[39m, in \u001b[36mGptOssForCausalLM_forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_router_logits, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    571\u001b[39m output_router_logits = (\n\u001b[32m    572\u001b[39m     output_router_logits \u001b[38;5;28;01mif\u001b[39;00m output_router_logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_router_logits\n\u001b[32m    573\u001b[39m )\n\u001b[32m    575\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m576\u001b[39m outputs: MoeModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_router_logits\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_router_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    586\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    588\u001b[39m hidden_states = outputs.last_hidden_state\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/unsloth_zoo/temporary_patches/gpt_oss.py:1249\u001b[39m, in \u001b[36mpatch_GptOssModel.<locals>.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m   1247\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers:\n\u001b[32m   1248\u001b[39m     mask = attention_mask[decoder_layer.attention_type] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attention_mask, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m attention_mask\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1258\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1259\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1260\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/transformers/models/gpt_oss/modeling_gpt_oss.py:401\u001b[39m, in \u001b[36mGptOssDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    400\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m hidden_states, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    411\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    413\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/transformers/models/gpt_oss/modeling_gpt_oss.py:358\u001b[39m, in \u001b[36mGptOssAttention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, position_ids, **kwargs)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation != \u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    356\u001b[39m     attention_interface = ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m.config._attn_implementation]\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m attn_output, attn_weights = \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43ms_aux\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msinks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# diff with Llama\u001b[39;49;00m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m attn_output = attn_output.reshape(*input_shape, -\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m    373\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.o_proj(attn_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:832\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>.compile_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    829\u001b[39m _maybe_set_eval_frame(_callback_from_stance(callback))\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    834\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/unsloth_compiled_cache/unsloth_compiled_module_gpt_oss.py:416\u001b[39m, in \u001b[36meager_attention_forward\u001b[39m\u001b[34m(module, query, key, value, attention_mask, scaling, dropout, **kwargs)\u001b[39m\n\u001b[32m    412\u001b[39m     k_embed = _apply_rotary_emb(k, cos, sin)\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m \u001b[38;5;129m@torch\u001b[39m.compile(fullgraph = \u001b[38;5;28;01mTrue\u001b[39;00m, dynamic = \u001b[38;5;28;01mTrue\u001b[39;00m, options = torch_compile_options)\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34meager_attention_forward\u001b[39m(\n\u001b[32m    418\u001b[39m     module: nn.Module,\n\u001b[32m    419\u001b[39m     query: torch.Tensor,\n\u001b[32m    420\u001b[39m     key: torch.Tensor,\n\u001b[32m    421\u001b[39m     value: torch.Tensor,\n\u001b[32m    422\u001b[39m     attention_mask: Optional[torch.Tensor],\n\u001b[32m    423\u001b[39m     scaling: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[32m    424\u001b[39m     dropout: \u001b[38;5;28mfloat\u001b[39m = \u001b[32m0.0\u001b[39m,\n\u001b[32m    425\u001b[39m     **kwargs,\n\u001b[32m    426\u001b[39m ):\n\u001b[32m    427\u001b[39m     key_states = repeat_kv(key, module.num_key_value_groups)\n\u001b[32m    428\u001b[39m     value_states = repeat_kv(value, module.num_key_value_groups)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:1044\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1042\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m   1043\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1046\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/_functorch/aot_autograd.py:1130\u001b[39m, in \u001b[36maot_module_simplified.<locals>.forward\u001b[39m\u001b[34m(*runtime_args)\u001b[39m\n\u001b[32m   1128\u001b[39m full_args.extend(params_buffers_flat)\n\u001b[32m   1129\u001b[39m full_args.extend(runtime_args)\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:353\u001b[39m, in \u001b[36m_create_runtime_wrapper.<locals>.runtime_wrapper\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    351\u001b[39m         torch._C._set_grad_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    352\u001b[39m     record_runtime_wrapper_prologue_exit(cm)\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m     all_outs = \u001b[43mcall_func_at_runtime_with_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompiled_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_amp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteal_args\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m grad_enabled:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/utils.py:129\u001b[39m, in \u001b[36mcall_func_at_runtime_with_args\u001b[39m\u001b[34m(f, args, steal_args, disable_amp)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(f, \u001b[33m\"\u001b[39m\u001b[33m_boxed_call\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m         out = normalize_as_list(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    131\u001b[39m         \u001b[38;5;66;03m# TODO: Please remove soon\u001b[39;00m\n\u001b[32m    132\u001b[39m         \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670\u001b[39;00m\n\u001b[32m    133\u001b[39m         warnings.warn(\n\u001b[32m    134\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYour compiler for AOTAutograd is returning a function that doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt take boxed arguments. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    135\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPlease wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    136\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSee https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    137\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/_functorch/_aot_autograd/runtime_wrappers.py:526\u001b[39m, in \u001b[36mFunctionalizedRngRuntimeWrapper.post_compile.<locals>.wrapper\u001b[39m\u001b[34m(runtime_args)\u001b[39m\n\u001b[32m    519\u001b[39m     out = \u001b[38;5;28mself\u001b[39m._functionalized_rng_runtime_epilogue(\n\u001b[32m    520\u001b[39m         runtime_metadata,\n\u001b[32m    521\u001b[39m         out,\n\u001b[32m    522\u001b[39m         \u001b[38;5;66;03m# TODO: this won't be right for the backward when we convert the call_compiled_backward to use the wrapper\u001b[39;00m\n\u001b[32m    523\u001b[39m         runtime_metadata.num_forward_returns,\n\u001b[32m    524\u001b[39m     )\n\u001b[32m    525\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruntime_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/_inductor/output_code.py:613\u001b[39m, in \u001b[36mCompiledFxGraph.__call__\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    610\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m record_function(\n\u001b[32m    611\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m## Call CompiledFxGraph \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._fx_graph_cache_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ##\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    612\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcurrent_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    615\u001b[39m     get_runtime_metrics_context().finish()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/cti-model-training/.venv/lib/python3.11/site-packages/torch/_inductor/utils.py:2962\u001b[39m, in \u001b[36malign_inputs_from_check_idxs.<locals>.run\u001b[39m\u001b[34m(new_inputs)\u001b[39m\n\u001b[32m   2958\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(new_inputs: \u001b[38;5;28mlist\u001b[39m[InputType]) -> Any:\n\u001b[32m   2959\u001b[39m     old_tensors, new_tensors = copy_misaligned_inputs(\n\u001b[32m   2960\u001b[39m         new_inputs, inputs_to_check, mutated_input_idxs\n\u001b[32m   2961\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2962\u001b[39m     out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2964\u001b[39m     \u001b[38;5;66;03m# If a mutated tensor was cloned to be aligned, we need to reflect back the mutation to the\u001b[39;00m\n\u001b[32m   2965\u001b[39m     \u001b[38;5;66;03m# original tensor.\u001b[39;00m\n\u001b[32m   2966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(old_tensors):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/torchinductor_deleftheriou/au/caubra2bflxwme53wxgozij54dzsr2t76azng7ptnrzbvas7arxd.py:429\u001b[39m, in \u001b[36mRunner.call\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    427\u001b[39m ps0 = s0*s38\n\u001b[32m    428\u001b[39m ps1 = s89*s0*s38\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m pool2 = \u001b[43mempty_strided_cuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43ms89\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms0\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms30\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms38\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43ms89\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms30\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms50\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43ms89\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms0\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms30\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms50\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43ms89\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms30\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms38\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms50\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43ms89\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms0\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms30\u001b[49m\u001b[43m*\u001b[49m\u001b[43ms38\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    430\u001b[39m buf0 = alloc_from_pool(pool2, \u001b[32m0\u001b[39m, torch.bfloat16, (\u001b[32m1\u001b[39m, s30, s89, s0, s38), (s89*s0*s30*s38, s89*s0*s38, s0*s38, s38, \u001b[32m1\u001b[39m))\n\u001b[32m    431\u001b[39m \u001b[38;5;66;03m# Topologically Sorted Source Nodes: [getitem_4, hidden_states, key_states], Original ATen: [aten.unsqueeze, aten.expand, aten.clone]\u001b[39;00m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 115.06 GiB. GPU 0 has a total capacity of 79.18 GiB of which 57.85 GiB is free. Including non-PyTorch memory, this process has 21.32 GiB memory in use. Of the allocated memory 17.31 GiB is allocated by PyTorch, with 1.34 GiB allocated in private pools (e.g., CUDA Graphs), and 3.34 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "system_message = system_messages[\"malware\"]\n",
    "user_input = format_validation_example_for_inference(dataset[\"train\"][\"text\"][0])\n",
    "inference(model,\n",
    "          system_message, \n",
    "          user_input, \n",
    "          max_new_tokens=None,\n",
    "          temperature=0.6,\n",
    "          top_p=0.1,\n",
    "          repetition_penalty=1.1,\n",
    "          no_repeat_ngram_size=3,\n",
    "          do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a4bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
