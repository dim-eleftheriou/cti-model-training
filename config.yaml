#############################
# Data args & configuration #
#############################
system_message: "You are a helpful AI assistant that transforms Cyberthreat intelligence reports (CTI) into STIX2.1 bundles. You must return ONLY a STIX2.1 bundle as a json file with the appropriate keys. Transform the folowing CTI report into STIX2.1 bundle: "
chat_template: "llama-3.2"
instruction_part: "<|start_header_id|>user<|end_header_id|>"
response_part: "<|start_header_id|>assistant<|end_header_id|>"
# Filter dataset by number of tokens. It will be equal to max_seq_length if max_seq_length not None
filter_dataset: False

###################################
# Model selection & configuration #
###################################
model_loading_args:

  # If None the default will be used! Model's max_position_embeddings argument in config file. Default for Llama3.1 is 131072
  max_seq_length: 32768
  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+
  dtype: 
  # Use 4bit quantization to reduce memory usage.
  load_in_4bit: True
  # Use 8bit quantization to reduce memory usage.
  load_in_8bit: False
  # Select model name from huggingface
  model_name: meta-llama/Llama-3.2-1B #unsloth/Llama-3.2-1B

model_saving_args:

  # Select if trained model should be uploaded to hugging face
  push_to_hub: False
  # Select if trained model should be uploaded to hugging face in private mode
  private: True
  # Select model name to used for uploading to huggingface after training
  adapters_name: CTI-Lora-Model
  # Select if trained model should be saved as GGUF
  save_to_gguf: False
  # Select if trained model should be uploaded to hugging face in GGUF format
  push_to_hub_gguf: False
  # Quantization methods for GGUF saving
  quantization_method_gguf: ["not_quantized", "f16", "q8_0"]
  # Online directory for pushing model to hugging face
  online_directory: dim-eleftheriou
  # Online name
  online_name: DarkWatch

##################################
# Fine-tuning mode configuration #
##################################
fine_tuning_args:

  # Select the type of training to be performed. Must be either text_completion or continued_pre_training
  training_type: text_completion
  # Select if validation data should be used in training process
  use_validation_dataset: True
  # Add special tokens in training. It can increase too much the GPU consumption!
  special_tokens_list: []

###################
# LoRA parameters #
###################
lora_parameters:

  r: 8
  lora_alpha: 8
  lora_dropout: 0    # Supports any, but = 0 is optimized
  bias: none    # Supports any, but = "none" is optimized
  use_gradient_checkpointing: unsloth # True or "unsloth" for very long context
  use_rslora: True
  loftq_config: None
  # If continued_pre_training=True then all modules will be targeted.
  # Available modules are: "q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj", "lm_head", "embed_tokens"
  target_modules: 
    - q_proj
    - k_proj
    - v_proj
    - o_proj
    - gate_proj
    - up_proj
    - down_proj
    - lm_head

########################
# SFTTrainer arguments #
########################
sft_trainer_arguments:

  data_collator: DataCollatorForSeq2Seq
  # Select number of processes to use for processing the dataset.
  dataset_num_proc: 4
  # Apply packing to dataset for fixed length. Creates a ConstantLengthDataset. Can decrease significantly the training time.
  apply_packing: False # To be used only for continued pre-training, otherwise may affect a lot the accuracy of the model.

######################
# Training Arguments #
######################
training_arguments:

  per_device_train_batch_size: 1
  gradient_accumulation_steps: 16
  report_to: tensorboard
  warmup_ratio: 0.1
  num_train_epochs: 20
  learning_rate: 0.00005
  embedding_learning_rate: 0.000005
  logging_steps: 1
  optim: "adamw_8bit"
  weight_decay: 0.01
  lr_scheduler_type: "cosine"
  seed: 1234

  ########################
  # Evaluation Arguments #
  ########################
  fp16_full_eval: True
  per_device_eval_batch_size: 1
  eval_accumulation_steps: 16
  #eval_steps: 1
  eval_strategy: "steps"

  ####################
  # Saving arguments #
  ####################
  #logging_dir: "logs"
  logging_strategy: "steps"
  output_dir: "outputs"
  save_strategy: "best"
  metric_for_best_model: "loss"
  #load_best_model_at_end: True
  save_total_limit: 1